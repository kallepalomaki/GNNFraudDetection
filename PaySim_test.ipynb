{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2fda4b0-72ce-4e28-9c2a-b9d9248a6615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a sample Python script.\n",
    "import pandas as pd\n",
    "import torch\n",
    "device = torch.device('cpu')\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import dgl.function as fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f18b6091-298f-4e96-933a-64499e87ed3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         step      type     amount     nameOrig  oldbalanceOrg  \\\n",
      "48459       9   PAYMENT    8517.09  C1544276689        34047.0   \n",
      "2725634   211  CASH_OUT  123172.45   C262696422        71135.0   \n",
      "1989810   179  CASH_OUT   67226.13  C1226687628            0.0   \n",
      "3465072   257   PAYMENT   11726.26   C115245548            0.0   \n",
      "5733741   399   CASH_IN  184629.59   C337768760        24650.0   \n",
      "\n",
      "         newbalanceOrig     nameDest  oldbalanceDest  newbalanceDest  isFraud  \\\n",
      "48459          25529.91  M1412197367            0.00            0.00        0   \n",
      "2725634            0.00  C1748139871      7574089.96      7697262.41        0   \n",
      "1989810            0.00  C1780779622       269926.46       337152.60        0   \n",
      "3465072            0.00   M379507303            0.00            0.00        0   \n",
      "5733741       209279.59   C544985868       262663.25        78033.66        0   \n",
      "\n",
      "         isFlaggedFraud  \n",
      "48459                 0  \n",
      "2725634               0  \n",
      "1989810               0  \n",
      "3465072               0  \n",
      "5733741               0  \n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"../data/PaySim_kaggle.csv\")\n",
    "\n",
    "df=df.sample(n=5000000)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e65c8bcb-5856-4d91-9eb1-8a090c0b2556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud count: 6479\n",
      "Non-fraud count: 4994\n",
      "Fraud ratio: 0.5647\n",
      "Non-fraud ratio: 0.4353\n"
     ]
    }
   ],
   "source": [
    "# Set the proportion of non-fraud to remove (e.g., 50% of non-fraud instances)\n",
    "remove_fraction = 0.999\n",
    "\n",
    "# Separate the fraud and non-fraud instances\n",
    "fraud_df = df[df['isFraud'] == 1]\n",
    "non_fraud_df = df[df['isFraud'] == 0]\n",
    "\n",
    "# Randomly sample and remove 'remove_fraction' proportion of non-fraud instances\n",
    "non_fraud_to_remove = non_fraud_df.sample(frac=remove_fraction, random_state=42)\n",
    "\n",
    "# Drop the sampled non-fraud instances from the DataFrame\n",
    "df = df.drop(non_fraud_to_remove.index)\n",
    "\n",
    "# Verify the new balance\n",
    "label_counts = df['isFraud'].value_counts()\n",
    "fraud_ratio = label_counts[1] / len(df)\n",
    "non_fraud_ratio = label_counts[0] / len(df)\n",
    "\n",
    "print(f\"Fraud count: {label_counts[1]}\")\n",
    "print(f\"Non-fraud count: {label_counts[0]}\")\n",
    "print(f\"Fraud ratio: {fraud_ratio:.4f}\")\n",
    "print(f\"Non-fraud ratio: {non_fraud_ratio:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19c68098-4397-40d0-b946-7a0230703f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from unique user names to numeric IDs (nodes)\n",
    "user_mapping = {user: idx for idx, user in enumerate(set(df['nameOrig']).union(set(df['nameDest'])))}\n",
    "\n",
    "# Create edges between nameOrig and nameDest\n",
    "src = df['nameOrig'].map(user_mapping).values\n",
    "dst = df['nameDest'].map(user_mapping).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bfd81d5-b2e8-4941-bc11-f3bd4257dcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15207 18883  4361 ... 22414 17698  7701]\n"
     ]
    }
   ],
   "source": [
    "print(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5253dc18-6c5e-4523-ab68-d45b6984bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DGL graph from the source and destination nodes\n",
    "g = dgl.graph((src, dst))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8d8d10c-4b83-4564-a4d1-280fae10d4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add transaction amount as edge feature\n",
    "g.edata['amount'] = torch.tensor(df['amount'].values, dtype=torch.float32)\n",
    "\n",
    "# Optional: Add fraud information to edge features\n",
    "g.edata['isFraud'] = torch.tensor(df['isFraud'].values, dtype=torch.float32)\n",
    "\n",
    "# Initialize node features with zeros (this handles all nodes)\n",
    "num_nodes = g.num_nodes()\n",
    "balance_orig = torch.zeros(num_nodes, dtype=torch.float32)\n",
    "balance_dest = torch.zeros(num_nodes, dtype=torch.float32)\n",
    "\n",
    "for orig_user, balance in df[['nameOrig', 'oldbalanceOrg']].drop_duplicates().values:\n",
    "    balance_orig[user_mapping[orig_user]] = balance\n",
    "\n",
    "for dest_user, balance in df[['nameDest', 'oldbalanceDest']].drop_duplicates().values:\n",
    "    balance_dest[user_mapping[dest_user]] = balance\n",
    "\n",
    "node_features = torch.stack([balance_orig, balance_dest], dim=1)  # Changed to stack both features\n",
    "\n",
    "g.ndata['features'] = node_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e37e5f8-5d2f-492e-8fcc-db40ce4f3e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DGLGraph.num_edges of Graph(num_nodes=22859, num_edges=11473,\n",
       "      ndata_schemes={'features': Scheme(shape=(2,), dtype=torch.float32)}\n",
       "      edata_schemes={'amount': Scheme(shape=(), dtype=torch.float32), 'isFraud': Scheme(shape=(), dtype=torch.float32)})>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edata['isFraud'].shape\n",
    "#node_features.shape\n",
    "g.num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "788366e2-8e69-40f7-82d7-5bb92f9a1ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print graph information\n",
    "#print(g)\n",
    "\n",
    "# Visualize the graph using NetworkX (convert DGL graph to NetworkX for visualization)\n",
    "#nx_graph = g.to_networkx()\n",
    "\n",
    "# Optional: Visualize using a layout for better readability\n",
    "#pos = nx.spring_layout(nx_graph)  # Use a layout for better visualization\n",
    "#plt.figure(figsize=(12, 12))\n",
    "#nx.draw(nx_graph, pos, node_size=50, node_color='skyblue', font_size=10, with_labels=True)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe561538-118f-4c17-b6cc-54460d44f063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge Features (Transaction Amounts):\n",
      "tensor([3.3740e+01, 1.3933e+05, 2.9360e+06,  ..., 2.3375e+05, 6.5529e+05,\n",
      "        3.3155e+03])\n"
     ]
    }
   ],
   "source": [
    "# Assuming that you have edge features like transaction amounts or fraud status\n",
    "edge_features = g.edata.get('amount', None)  # Assuming 'amount' is an edge feature\n",
    "if edge_features is not None:\n",
    "    print(\"Edge Features (Transaction Amounts):\")\n",
    "    print(edge_features)\n",
    "else:\n",
    "    print(\"No edge features found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecd2e705-81a6-4e96-a46a-7e8af83ea77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = g.edges()\n",
    "# Split the dataset into train and test set\n",
    "# Generate indices for train-test split (80% train, 20% test)\n",
    "num_train_edges = int(0.8 * len(edges[0]))\n",
    "train_indices = torch.arange(num_train_edges)\n",
    "test_indices = torch.arange(num_train_edges, len(edges[0]))\n",
    "\n",
    "# Create masks for training and testing\n",
    "train_mask = torch.zeros(len(edges[0]), dtype=torch.bool)\n",
    "test_mask = torch.zeros(len(edges[0]), dtype=torch.bool)\n",
    "train_mask[train_indices] = 1\n",
    "test_mask[test_indices] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b521fd7-bdfd-47eb-a894-4f4175fd2ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GraphSAGE model for fraud detection\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_feats, out_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.layer1 = dgl.nn.SAGEConv(in_feats, hidden_feats, 'mean')\n",
    "        self.layer2 = dgl.nn.SAGEConv(hidden_feats, out_feats, 'mean')\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(out_feats * 2, 1)  # * Concatenate source and destination node embeddings *\n",
    "        \n",
    "    def forward(self, g, features):\n",
    "        # Apply first GraphSAGE layer and ReLU\n",
    "        x = self.layer1(g, features)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Apply second GraphSAGE layer to get embeddings\n",
    "        x = self.layer2(g, x)\n",
    "        \n",
    "        # Get source and destination nodes for each edge\n",
    "        src, dst = g.edges()  # Get indices of source and destination nodes\n",
    "        src_embeddings = x[src]  # Embeddings for source nodes\n",
    "        dst_embeddings = x[dst]  # Embeddings for destination nodes\n",
    "        \n",
    "        # Concatenate source and destination node embeddings to create edge features\n",
    "        edge_features = torch.cat([src_embeddings, dst_embeddings], dim=1)  # Concatenate along the feature dimension\n",
    "        logits = self.fc(edge_features).squeeze()  # * Output a single value per edge (fraud score) *\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "caf5f966-4635-469e-a2d6-2bf70d46c371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud count: 6479\n",
      "Non-fraud count: 4994\n",
      "Fraud ratio: 0.5647\n",
      "Non-fraud ratio: 0.4353\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each label in the 'isFraud' column\n",
    "label_counts = df['isFraud'].value_counts()\n",
    "\n",
    "# Calculate the proportion of each class\n",
    "fraud_ratio = label_counts[1] / len(df)  # Assuming '1' represents fraud\n",
    "non_fraud_ratio = label_counts[0] / len(df)  # Assuming '0' represents non-fraud\n",
    "\n",
    "# Print the results\n",
    "print(f\"Fraud count: {label_counts[1]}\")\n",
    "print(f\"Non-fraud count: {label_counts[0]}\")\n",
    "print(f\"Fraud ratio: {fraud_ratio:.4f}\")\n",
    "print(f\"Non-fraud ratio: {non_fraud_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f542233-e155-4918-8816-b1e3e427d999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11473])\n",
      "torch.Size([11473])\n",
      "Epoch 2/20, Loss: 94931.5625\n",
      "torch.Size([11473])\n",
      "torch.Size([11473])\n",
      "Epoch 4/20, Loss: 64249.4921875\n",
      "torch.Size([11473])\n",
      "torch.Size([11473])\n",
      "Epoch 6/20, Loss: 63201.98046875\n",
      "torch.Size([11473])\n",
      "torch.Size([11473])\n",
      "Epoch 8/20, Loss: 55559.6875\n",
      "torch.Size([11473])\n",
      "torch.Size([11473])\n",
      "Epoch 10/20, Loss: 43335.390625\n",
      "torch.Size([11473])\n",
      "torch.Size([11473])\n",
      "Epoch 12/20, Loss: 37003.17578125\n",
      "torch.Size([11473])\n",
      "torch.Size([11473])\n",
      "Epoch 14/20, Loss: 28193.98046875\n",
      "torch.Size([11473])\n",
      "torch.Size([11473])\n",
      "Epoch 16/20, Loss: 22054.80859375\n",
      "torch.Size([11473])\n",
      "torch.Size([11473])\n",
      "Epoch 18/20, Loss: 18774.625\n",
      "torch.Size([11473])\n",
      "torch.Size([11473])\n",
      "Epoch 20/20, Loss: 18044.1015625\n",
      "Accuracy: 0.6118\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'predicte_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 61\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Calculate F1-Score\u001b[39;00m\n\u001b[1;32m     60\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(true_labels, predicted_labels)\n\u001b[0;32m---> 61\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_score(true_labels, \u001b[43mpredicte_labels\u001b[49m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predicte_labels' is not defined"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "in_feats = 2  # balanceOrig and balanceDest features\n",
    "hidden_feats = 64\n",
    "out_feats = 1  # Fraud (binary classification)\n",
    "\n",
    "model = GraphSAGE(in_feats, hidden_feats, out_feats)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    # Forward pass\n",
    "    logits = model(g, g.ndata['features'])\n",
    "    print(logits.shape)\n",
    "\n",
    "    # Get target labels for the fraud detection task\n",
    "    labels = g.edata['isFraud']\n",
    "    breakpoint()\n",
    "    # Compute loss (use train_mask to filter out test edges)\n",
    "    labels[train_mask]\n",
    "\n",
    "    logits[train_mask]\n",
    "    loss = loss_fn(logits[train_mask], labels[train_mask])\n",
    "    \n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss every few epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(g, g.ndata['features'])\n",
    "\n",
    "    # Convert logits to probabilities\n",
    "    predictions = torch.sigmoid(logits).squeeze()\n",
    "    \n",
    "    # Apply threshold of 0.5 to classify fraud\n",
    "    predicted_labels = (predictions > 0.5).float()\n",
    "    predicted_labels = predicted_labels[test_mask]  # Apply test_mask here\n",
    "    # Get actual labels\n",
    "    #true_labels = g.edata['isFraud']\n",
    "    true_labels = g.edata['isFraud'][test_mask]  # Apply test_mask here\n",
    "    # Compute accuracy manually\n",
    "    correct = (predicted_labels == true_labels).sum().item()\n",
    "    total = true_labels.size(0)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    # Print evaluation results\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    # Calculate F1-Score\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "\n",
    "    print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207ba890-7fc4-4444-a169-f08dfebd5356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e038e1d4-80f5-40f4-a2ed-8af5c8796f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecd1b59-7534-49cf-8886-b8a80e74a718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
