{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2fda4b0-72ce-4e28-9c2a-b9d9248a6615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a sample Python script.\n",
    "import pandas as pd\n",
    "import torch\n",
    "device = torch.device('cpu')\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import dgl.function as fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f18b6091-298f-4e96-933a-64499e87ed3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         step      type     amount     nameOrig  oldbalanceOrg  \\\n",
      "870109     42  TRANSFER  242562.56   C325477060        56855.0   \n",
      "3069529   235  CASH_OUT  111562.59  C2097803603        13308.0   \n",
      "2820471   226  CASH_OUT  438012.14  C1117799938        11168.0   \n",
      "4090493   301  CASH_OUT  139127.36  C1388404688            0.0   \n",
      "207098     13   PAYMENT    5870.47   C906298338            0.0   \n",
      "\n",
      "         newbalanceOrig     nameDest  oldbalanceDest  newbalanceDest  isFraud  \\\n",
      "870109              0.0  C2091358494      5994182.62      5913818.03        0   \n",
      "3069529             0.0   C423176779        39176.87       150739.45        0   \n",
      "2820471             0.0   C620340952         2011.42       440023.55        0   \n",
      "4090493             0.0   C455282885      2805419.15      2944546.51        0   \n",
      "207098              0.0   M367751351            0.00            0.00        0   \n",
      "\n",
      "         isFlaggedFraud  \n",
      "870109                0  \n",
      "3069529               0  \n",
      "2820471               0  \n",
      "4090493               0  \n",
      "207098                0  \n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"../data/PaySim_kaggle.csv\")\n",
    "\n",
    "df=df.sample(n=5000000)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e65c8bcb-5856-4d91-9eb1-8a090c0b2556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud count: 6451\n",
      "Non-fraud count: 4994\n",
      "Fraud ratio: 0.5637\n",
      "Non-fraud ratio: 0.4363\n"
     ]
    }
   ],
   "source": [
    "# Set the proportion of non-fraud to remove (e.g., 50% of non-fraud instances)\n",
    "remove_fraction = 0.999\n",
    "\n",
    "# Separate the fraud and non-fraud instances\n",
    "fraud_df = df[df['isFraud'] == 1]\n",
    "non_fraud_df = df[df['isFraud'] == 0]\n",
    "\n",
    "# Randomly sample and remove 'remove_fraction' proportion of non-fraud instances\n",
    "non_fraud_to_remove = non_fraud_df.sample(frac=remove_fraction, random_state=42)\n",
    "\n",
    "# Drop the sampled non-fraud instances from the DataFrame\n",
    "df = df.drop(non_fraud_to_remove.index)\n",
    "\n",
    "# Verify the new balance\n",
    "label_counts = df['isFraud'].value_counts()\n",
    "fraud_ratio = label_counts[1] / len(df)\n",
    "non_fraud_ratio = label_counts[0] / len(df)\n",
    "\n",
    "print(f\"Fraud count: {label_counts[1]}\")\n",
    "print(f\"Non-fraud count: {label_counts[0]}\")\n",
    "print(f\"Fraud ratio: {fraud_ratio:.4f}\")\n",
    "print(f\"Non-fraud ratio: {non_fraud_ratio:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19c68098-4397-40d0-b946-7a0230703f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from unique user names to numeric IDs (nodes)\n",
    "user_mapping = {user: idx for idx, user in enumerate(set(df['nameOrig']).union(set(df['nameDest'])))}\n",
    "\n",
    "# Create edges between nameOrig and nameDest\n",
    "src = df['nameOrig'].map(user_mapping).values\n",
    "dst = df['nameDest'].map(user_mapping).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bfd81d5-b2e8-4941-bc11-f3bd4257dcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21407 20441 21549 ...   863 10173  9496]\n"
     ]
    }
   ],
   "source": [
    "print(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5253dc18-6c5e-4523-ab68-d45b6984bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DGL graph from the source and destination nodes\n",
    "g = dgl.graph((src, dst))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8d8d10c-4b83-4564-a4d1-280fae10d4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add transaction amount as edge feature\n",
    "g.edata['amount'] = torch.tensor(df['amount'].values, dtype=torch.float32)\n",
    "\n",
    "# Optional: Add fraud information to edge features\n",
    "g.edata['isFraud'] = torch.tensor(df['isFraud'].values, dtype=torch.float32)\n",
    "\n",
    "# Initialize node features with zeros (this handles all nodes)\n",
    "num_nodes = g.num_nodes()\n",
    "balance_orig = torch.zeros(num_nodes, dtype=torch.float32)\n",
    "balance_dest = torch.zeros(num_nodes, dtype=torch.float32)\n",
    "\n",
    "for orig_user, balance in df[['nameOrig', 'oldbalanceOrg']].drop_duplicates().values:\n",
    "    balance_orig[user_mapping[orig_user]] = balance\n",
    "\n",
    "for dest_user, balance in df[['nameDest', 'oldbalanceDest']].drop_duplicates().values:\n",
    "    balance_dest[user_mapping[dest_user]] = balance\n",
    "\n",
    "node_features = torch.stack([balance_orig, balance_dest], dim=1)  # Changed to stack both features\n",
    "\n",
    "g.ndata['features'] = node_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e37e5f8-5d2f-492e-8fcc-db40ce4f3e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DGLGraph.num_edges of Graph(num_nodes=22805, num_edges=11445,\n",
       "      ndata_schemes={'features': Scheme(shape=(2,), dtype=torch.float32)}\n",
       "      edata_schemes={'amount': Scheme(shape=(), dtype=torch.float32), 'isFraud': Scheme(shape=(), dtype=torch.float32)})>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edata['isFraud'].shape\n",
    "#node_features.shape\n",
    "g.num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "788366e2-8e69-40f7-82d7-5bb92f9a1ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print graph information\n",
    "#print(g)\n",
    "\n",
    "# Visualize the graph using NetworkX (convert DGL graph to NetworkX for visualization)\n",
    "#nx_graph = g.to_networkx()\n",
    "\n",
    "# Optional: Visualize using a layout for better readability\n",
    "#pos = nx.spring_layout(nx_graph)  # Use a layout for better visualization\n",
    "#plt.figure(figsize=(12, 12))\n",
    "#nx.draw(nx_graph, pos, node_size=50, node_color='skyblue', font_size=10, with_labels=True)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe561538-118f-4c17-b6cc-54460d44f063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge Features (Transaction Amounts):\n",
      "tensor([1.5655e+03, 2.3467e+05, 3.0853e+06,  ..., 3.0810e+06, 4.8728e+05,\n",
      "        8.4320e+05])\n"
     ]
    }
   ],
   "source": [
    "# Assuming that you have edge features like transaction amounts or fraud status\n",
    "edge_features = g.edata.get('amount', None)  # Assuming 'amount' is an edge feature\n",
    "if edge_features is not None:\n",
    "    print(\"Edge Features (Transaction Amounts):\")\n",
    "    print(edge_features)\n",
    "else:\n",
    "    print(\"No edge features found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecd2e705-81a6-4e96-a46a-7e8af83ea77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = g.edges()\n",
    "# Split the dataset into train and test set\n",
    "# Generate indices for train-test split (80% train, 20% test)\n",
    "num_train_edges = int(0.8 * len(edges[0]))\n",
    "train_indices = torch.arange(num_train_edges)\n",
    "test_indices = torch.arange(num_train_edges, len(edges[0]))\n",
    "\n",
    "# Create masks for training and testing\n",
    "train_mask = torch.zeros(len(edges[0]), dtype=torch.bool)\n",
    "test_mask = torch.zeros(len(edges[0]), dtype=torch.bool)\n",
    "train_mask[train_indices] = 1\n",
    "test_mask[test_indices] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b521fd7-bdfd-47eb-a894-4f4175fd2ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GraphSAGE model for fraud detection\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_feats, out_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.layer1 = dgl.nn.SAGEConv(in_feats, hidden_feats, 'mean')\n",
    "        self.layer2 = dgl.nn.SAGEConv(hidden_feats, out_feats, 'mean')\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(out_feats * 2, 1)  # * Concatenate source and destination node embeddings *\n",
    "        \n",
    "    def forward(self, g, features):\n",
    "        # Apply first GraphSAGE layer and ReLU\n",
    "        x = self.layer1(g, features)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Apply second GraphSAGE layer to get embeddings\n",
    "        x = self.layer2(g, x)\n",
    "        \n",
    "        # Get source and destination nodes for each edge\n",
    "        src, dst = g.edges()  # Get indices of source and destination nodes\n",
    "        src_embeddings = x[src]  # Embeddings for source nodes\n",
    "        dst_embeddings = x[dst]  # Embeddings for destination nodes\n",
    "        \n",
    "        # Concatenate source and destination node embeddings to create edge features\n",
    "        edge_features = torch.cat([src_embeddings, dst_embeddings], dim=1)  # Concatenate along the feature dimension\n",
    "        logits = self.fc(edge_features).squeeze()  # * Output a single value per edge (fraud score) *\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caf5f966-4635-469e-a2d6-2bf70d46c371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud count: 6451\n",
      "Non-fraud count: 4994\n",
      "Fraud ratio: 0.5637\n",
      "Non-fraud ratio: 0.4363\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each label in the 'isFraud' column\n",
    "label_counts = df['isFraud'].value_counts()\n",
    "\n",
    "# Calculate the proportion of each class\n",
    "fraud_ratio = label_counts[1] / len(df)  # Assuming '1' represents fraud\n",
    "non_fraud_ratio = label_counts[0] / len(df)  # Assuming '0' represents non-fraud\n",
    "\n",
    "# Print the results\n",
    "print(f\"Fraud count: {label_counts[1]}\")\n",
    "print(f\"Non-fraud count: {label_counts[0]}\")\n",
    "print(f\"Fraud ratio: {fraud_ratio:.4f}\")\n",
    "print(f\"Non-fraud ratio: {non_fraud_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f542233-e155-4918-8816-b1e3e427d999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11445])\n",
      "torch.Size([11445])\n",
      "Epoch 2/20, Loss: 231100.96875\n",
      "torch.Size([11445])\n",
      "torch.Size([11445])\n",
      "Epoch 4/20, Loss: 220659.8125\n",
      "torch.Size([11445])\n",
      "torch.Size([11445])\n",
      "Epoch 6/20, Loss: 181651.75\n",
      "torch.Size([11445])\n",
      "torch.Size([11445])\n",
      "Epoch 8/20, Loss: 164662.9375\n",
      "torch.Size([11445])\n",
      "torch.Size([11445])\n",
      "Epoch 10/20, Loss: 150651.921875\n",
      "torch.Size([11445])\n",
      "torch.Size([11445])\n",
      "Epoch 12/20, Loss: 145042.25\n",
      "torch.Size([11445])\n",
      "torch.Size([11445])\n",
      "Epoch 14/20, Loss: 120622.2890625\n",
      "torch.Size([11445])\n",
      "torch.Size([11445])\n",
      "Epoch 16/20, Loss: 112228.1484375\n",
      "torch.Size([11445])\n",
      "torch.Size([11445])\n",
      "Epoch 18/20, Loss: 99935.4375\n",
      "torch.Size([11445])\n",
      "torch.Size([11445])\n",
      "Epoch 20/20, Loss: 90070.9140625\n",
      "Accuracy: 0.6994\n",
      "F1 Score: 0.7593\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "in_feats = 2  # balanceOrig and balanceDest features\n",
    "hidden_feats = 64\n",
    "out_feats = 1  # Fraud (binary classification)\n",
    "\n",
    "model = GraphSAGE(in_feats, hidden_feats, out_feats)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    # Forward pass\n",
    "    logits = model(g, g.ndata['features'])\n",
    "    print(logits.shape)\n",
    "\n",
    "    # Get target labels for the fraud detection task\n",
    "    labels = g.edata['isFraud']\n",
    "    breakpoint()\n",
    "    # Compute loss (use train_mask to filter out test edges)\n",
    "    labels[train_mask]\n",
    "\n",
    "    logits[train_mask]\n",
    "    loss = loss_fn(logits[train_mask], labels[train_mask])\n",
    "    \n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss every few epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(g, g.ndata['features'])\n",
    "\n",
    "    # Convert logits to probabilities\n",
    "    predictions = torch.sigmoid(logits).squeeze()\n",
    "    \n",
    "    # Apply threshold of 0.5 to classify fraud\n",
    "    predicted_labels = (predictions > 0.5).float()\n",
    "    predicted_labels = predicted_labels[test_mask]  # Apply test_mask here\n",
    "    # Get actual labels\n",
    "    #true_labels = g.edata['isFraud']\n",
    "    true_labels = g.edata['isFraud'][test_mask]  # Apply test_mask here\n",
    "    # Compute accuracy manually\n",
    "    correct = (predicted_labels == true_labels).sum().item()\n",
    "    total = true_labels.size(0)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    # Print evaluation results\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    # Calculate F1-Score\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "    print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207ba890-7fc4-4444-a169-f08dfebd5356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e038e1d4-80f5-40f4-a2ed-8af5c8796f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecd1b59-7534-49cf-8886-b8a80e74a718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
