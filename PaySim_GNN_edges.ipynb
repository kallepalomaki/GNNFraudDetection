{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2fda4b0-72ce-4e28-9c2a-b9d9248a6615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a sample Python script.\n",
    "import pandas as pd\n",
    "import torch\n",
    "device = torch.device('cpu')\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import dgl.function as fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f18b6091-298f-4e96-933a-64499e87ed3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         step      type     amount     nameOrig  oldbalanceOrg  \\\n",
      "5833298   402   PAYMENT   16663.31   C376362460       68255.17   \n",
      "740242     38   CASH_IN  366824.91  C1092369823       11653.00   \n",
      "6032727   474   PAYMENT    3335.39  C1731599343           0.00   \n",
      "5617036   395  CASH_OUT  284818.10   C613449053       18677.00   \n",
      "1551687   154  CASH_OUT   78014.47  C2085758934         148.00   \n",
      "\n",
      "         newbalanceOrig     nameDest  oldbalanceDest  newbalanceDest  isFraud  \\\n",
      "5833298        51591.86  M1472741442            0.00            0.00        0   \n",
      "740242        378477.91   C670698587            0.00            0.00        0   \n",
      "6032727            0.00  M1392062286            0.00            0.00        0   \n",
      "5617036            0.00   C933740624       935226.32      1220044.42        0   \n",
      "1551687            0.00  C2130767207            0.00        78014.47        0   \n",
      "\n",
      "         isFlaggedFraud  \n",
      "5833298               0  \n",
      "740242                0  \n",
      "6032727               0  \n",
      "5617036               0  \n",
      "1551687               0  \n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"../data/PaySim_kaggle.csv\")\n",
    "\n",
    "df=df.sample(n=5000000)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483aa886-0429-41e6-b6d2-120bba8f5c02",
   "metadata": {},
   "source": [
    "Adjust data proportions as the fraud data is heavily biased having less fraudulant cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e65c8bcb-5856-4d91-9eb1-8a090c0b2556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud count: 6423\n",
      "Non-fraud count: 49936\n",
      "Fraud ratio: 0.1140\n",
      "Non-fraud ratio: 0.8860\n"
     ]
    }
   ],
   "source": [
    "# Set the proportion of non-fraud to remove (e.g., 50% of non-fraud instances)\n",
    "remove_fraction = 0.99\n",
    "\n",
    "# Separate the fraud and non-fraud instances\n",
    "fraud_df = df[df['isFraud'] == 1]\n",
    "non_fraud_df = df[df['isFraud'] == 0]\n",
    "\n",
    "# Randomly sample and remove 'remove_fraction' proportion of non-fraud instances\n",
    "non_fraud_to_remove = non_fraud_df.sample(frac=remove_fraction, random_state=42)\n",
    "\n",
    "# Drop the sampled non-fraud instances from the DataFrame\n",
    "df = df.drop(non_fraud_to_remove.index)\n",
    "\n",
    "# Verify the new balance\n",
    "label_counts = df['isFraud'].value_counts()\n",
    "fraud_ratio = label_counts[1] / len(df)\n",
    "non_fraud_ratio = label_counts[0] / len(df)\n",
    "\n",
    "print(f\"Fraud count: {label_counts[1]}\")\n",
    "print(f\"Non-fraud count: {label_counts[0]}\")\n",
    "print(f\"Fraud ratio: {fraud_ratio:.4f}\")\n",
    "print(f\"Non-fraud ratio: {non_fraud_ratio:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19c68098-4397-40d0-b946-7a0230703f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from unique user names to numeric IDs (nodes)\n",
    "user_mapping = {user: idx for idx, user in enumerate(set(df['nameOrig']).union(set(df['nameDest'])))}\n",
    "\n",
    "# Create edges between nameOrig and nameDest\n",
    "src = df['nameOrig'].map(user_mapping).values\n",
    "dst = df['nameDest'].map(user_mapping).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bfd81d5-b2e8-4941-bc11-f3bd4257dcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53133 66976 87427 ... 45822 19224 21063]\n"
     ]
    }
   ],
   "source": [
    "print(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5253dc18-6c5e-4523-ab68-d45b6984bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DGL graph from the source and destination nodes\n",
    "g = dgl.graph((src, dst))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8d8d10c-4b83-4564-a4d1-280fae10d4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add transaction amount as edge feature\n",
    "g.edata['amount'] = torch.tensor(df['amount'].values, dtype=torch.float32)\n",
    "\n",
    "# Optional: Add fraud information to edge features\n",
    "g.edata['isFraud'] = torch.tensor(df['isFraud'].values, dtype=torch.float32)\n",
    "\n",
    "# Initialize node features with zeros (this handles all nodes)\n",
    "num_nodes = g.num_nodes()\n",
    "balance_orig = torch.zeros(num_nodes, dtype=torch.float32)\n",
    "balance_dest = torch.zeros(num_nodes, dtype=torch.float32)\n",
    "\n",
    "for orig_user, balance in df[['nameOrig', 'oldbalanceOrg']].drop_duplicates().values:\n",
    "    balance_orig[user_mapping[orig_user]] = balance\n",
    "\n",
    "for dest_user, balance in df[['nameDest', 'oldbalanceDest']].drop_duplicates().values:\n",
    "    balance_dest[user_mapping[dest_user]] = balance\n",
    "\n",
    "node_features = torch.stack([balance_orig, balance_dest], dim=1)  # Changed to stack both features\n",
    "\n",
    "g.ndata['features'] = node_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e37e5f8-5d2f-492e-8fcc-db40ce4f3e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DGLGraph.num_edges of Graph(num_nodes=110593, num_edges=56359,\n",
       "      ndata_schemes={'features': Scheme(shape=(2,), dtype=torch.float32)}\n",
       "      edata_schemes={'amount': Scheme(shape=(), dtype=torch.float32), 'isFraud': Scheme(shape=(), dtype=torch.float32)})>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edata['isFraud'].shape\n",
    "#node_features.shape\n",
    "g.num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "788366e2-8e69-40f7-82d7-5bb92f9a1ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print graph information\n",
    "#print(g)\n",
    "\n",
    "# Visualize the graph using NetworkX (convert DGL graph to NetworkX for visualization)\n",
    "#nx_graph = g.to_networkx()\n",
    "\n",
    "# Optional: Visualize using a layout for better readability\n",
    "#pos = nx.spring_layout(nx_graph)  # Use a layout for better visualization\n",
    "#plt.figure(figsize=(12, 12))\n",
    "#nx.draw(nx_graph, pos, node_size=50, node_color='skyblue', font_size=10, with_labels=True)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe561538-118f-4c17-b6cc-54460d44f063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge Features (Transaction Amounts):\n",
      "tensor([7.5386e+04, 6.6723e+05, 4.4791e+04,  ..., 3.0052e+05, 4.7404e+02,\n",
      "        4.1814e+04])\n"
     ]
    }
   ],
   "source": [
    "# Assuming that you have edge features like transaction amounts or fraud status\n",
    "edge_features = g.edata.get('amount', None)  # Assuming 'amount' is an edge feature\n",
    "if edge_features is not None:\n",
    "    print(\"Edge Features (Transaction Amounts):\")\n",
    "    print(edge_features)\n",
    "else:\n",
    "    print(\"No edge features found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecd2e705-81a6-4e96-a46a-7e8af83ea77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = g.edges()\n",
    "# Split the dataset into train and test set\n",
    "# Generate indices for train-test split (80% train, 20% test)\n",
    "num_train_edges = int(0.8 * len(edges[0]))\n",
    "train_indices = torch.arange(num_train_edges)\n",
    "test_indices = torch.arange(num_train_edges, len(edges[0]))\n",
    "\n",
    "# Create masks for training and testing\n",
    "train_mask = torch.zeros(len(edges[0]), dtype=torch.bool)\n",
    "test_mask = torch.zeros(len(edges[0]), dtype=torch.bool)\n",
    "train_mask[train_indices] = 1\n",
    "test_mask[test_indices] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b521fd7-bdfd-47eb-a894-4f4175fd2ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GraphSAGE model for fraud detection\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_feats, out_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.layer1 = dgl.nn.SAGEConv(in_feats, hidden_feats, 'mean')\n",
    "        self.layer2 = dgl.nn.SAGEConv(hidden_feats, out_feats, 'mean')\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(out_feats * 2, 1)  # * Concatenate source and destination node embeddings *\n",
    "        \n",
    "    def forward(self, g, features):\n",
    "        # Apply first GraphSAGE layer and ReLU\n",
    "        x = self.layer1(g, features)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Apply second GraphSAGE layer to get embeddings\n",
    "        x = self.layer2(g, x)\n",
    "        \n",
    "        # Get source and destination nodes for each edge\n",
    "        src, dst = g.edges()  # Get indices of source and destination nodes\n",
    "        src_embeddings = x[src]  # Embeddings for source nodes\n",
    "        dst_embeddings = x[dst]  # Embeddings for destination nodes\n",
    "        \n",
    "        # Concatenate source and destination node embeddings to create edge features\n",
    "        edge_features = torch.cat([src_embeddings, dst_embeddings], dim=1)  # Concatenate along the feature dimension\n",
    "        logits = self.fc(edge_features).squeeze()  # * Output a single value per edge (fraud score) *\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "caf5f966-4635-469e-a2d6-2bf70d46c371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud count: 6423\n",
      "Non-fraud count: 49936\n",
      "Fraud ratio: 0.1140\n",
      "Non-fraud ratio: 0.8860\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each label in the 'isFraud' column\n",
    "label_counts = df['isFraud'].value_counts()\n",
    "\n",
    "# Calculate the proportion of each class\n",
    "fraud_ratio = label_counts[1] / len(df)  # Assuming '1' represents fraud\n",
    "non_fraud_ratio = label_counts[0] / len(df)  # Assuming '0' represents non-fraud\n",
    "\n",
    "# Print the results\n",
    "print(f\"Fraud count: {label_counts[1]}\")\n",
    "print(f\"Non-fraud count: {label_counts[0]}\")\n",
    "print(f\"Fraud ratio: {fraud_ratio:.4f}\")\n",
    "print(f\"Non-fraud ratio: {non_fraud_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9f542233-e155-4918-8816-b1e3e427d999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200, Loss: 443286.6875\n",
      "Epoch 4/200, Loss: 330277.40625\n",
      "Epoch 6/200, Loss: 240058.8125\n",
      "Epoch 8/200, Loss: 232801.71875\n",
      "Epoch 10/200, Loss: 227355.984375\n",
      "Epoch 12/200, Loss: 212179.6875\n",
      "Epoch 14/200, Loss: 174467.9375\n",
      "Epoch 16/200, Loss: 157055.703125\n",
      "Epoch 18/200, Loss: 123834.6953125\n",
      "Epoch 20/200, Loss: 100676.6953125\n",
      "Epoch 22/200, Loss: 91932.4140625\n",
      "Epoch 24/200, Loss: 90944.578125\n",
      "Epoch 26/200, Loss: 76480.8203125\n",
      "Epoch 28/200, Loss: 76917.21875\n",
      "Epoch 30/200, Loss: 60013.40234375\n",
      "Epoch 32/200, Loss: 50517.64453125\n",
      "Epoch 34/200, Loss: 45130.55859375\n",
      "Epoch 36/200, Loss: 36097.92578125\n",
      "Epoch 38/200, Loss: 33103.75\n",
      "Epoch 40/200, Loss: 34758.8671875\n",
      "Epoch 42/200, Loss: 37220.44921875\n",
      "Epoch 44/200, Loss: 25694.14453125\n",
      "Epoch 46/200, Loss: 24046.47265625\n",
      "Epoch 48/200, Loss: 22496.0625\n",
      "Epoch 50/200, Loss: 18533.373046875\n",
      "Epoch 52/200, Loss: 19977.6953125\n",
      "Epoch 54/200, Loss: 17224.845703125\n",
      "Epoch 56/200, Loss: 15881.20703125\n",
      "Epoch 58/200, Loss: 13609.921875\n",
      "Epoch 60/200, Loss: 15090.494140625\n",
      "Epoch 62/200, Loss: 12149.3994140625\n",
      "Epoch 64/200, Loss: 10475.7412109375\n",
      "Epoch 66/200, Loss: 10376.25390625\n",
      "Epoch 68/200, Loss: 9336.87890625\n",
      "Epoch 70/200, Loss: 9733.13671875\n",
      "Epoch 72/200, Loss: 8200.701171875\n",
      "Epoch 74/200, Loss: 7907.85400390625\n",
      "Epoch 76/200, Loss: 8304.2802734375\n",
      "Epoch 78/200, Loss: 8271.57421875\n",
      "Epoch 80/200, Loss: 8448.8828125\n",
      "Epoch 82/200, Loss: 6056.34423828125\n",
      "Epoch 84/200, Loss: 6654.12890625\n",
      "Epoch 86/200, Loss: 6585.96240234375\n",
      "Epoch 88/200, Loss: 5385.30419921875\n",
      "Epoch 90/200, Loss: 6062.326171875\n",
      "Epoch 92/200, Loss: 5883.2978515625\n",
      "Epoch 94/200, Loss: 4475.98095703125\n",
      "Epoch 96/200, Loss: 4166.6533203125\n",
      "Epoch 98/200, Loss: 4575.197265625\n",
      "Epoch 100/200, Loss: 3556.903564453125\n",
      "Epoch 102/200, Loss: 3736.09765625\n",
      "Epoch 104/200, Loss: 3754.34130859375\n",
      "Epoch 106/200, Loss: 2993.655517578125\n",
      "Epoch 108/200, Loss: 3202.877685546875\n",
      "Epoch 110/200, Loss: 3824.521240234375\n",
      "Epoch 112/200, Loss: 3485.082275390625\n",
      "Epoch 114/200, Loss: 3071.9873046875\n",
      "Epoch 116/200, Loss: 2570.318115234375\n",
      "Epoch 118/200, Loss: 2533.787353515625\n",
      "Epoch 120/200, Loss: 2362.26318359375\n",
      "Epoch 122/200, Loss: 2324.218017578125\n",
      "Epoch 124/200, Loss: 2336.918701171875\n",
      "Epoch 126/200, Loss: 2103.37744140625\n",
      "Epoch 128/200, Loss: 1904.601806640625\n",
      "Epoch 130/200, Loss: 2232.72509765625\n",
      "Epoch 132/200, Loss: 2055.644287109375\n",
      "Epoch 134/200, Loss: 1596.938232421875\n",
      "Epoch 136/200, Loss: 2023.6839599609375\n",
      "Epoch 138/200, Loss: 1339.2125244140625\n",
      "Epoch 140/200, Loss: 1856.0301513671875\n",
      "Epoch 142/200, Loss: 1540.0894775390625\n",
      "Epoch 144/200, Loss: 1439.6787109375\n",
      "Epoch 146/200, Loss: 1493.0146484375\n",
      "Epoch 148/200, Loss: 1104.110595703125\n",
      "Epoch 150/200, Loss: 1294.8956298828125\n",
      "Epoch 152/200, Loss: 1274.6529541015625\n",
      "Epoch 154/200, Loss: 1186.2515869140625\n",
      "Epoch 156/200, Loss: 951.6795654296875\n",
      "Epoch 158/200, Loss: 924.3552856445312\n",
      "Epoch 160/200, Loss: 813.1213989257812\n",
      "Epoch 162/200, Loss: 740.0964965820312\n",
      "Epoch 164/200, Loss: 759.1425170898438\n",
      "Epoch 166/200, Loss: 901.89697265625\n",
      "Epoch 168/200, Loss: 711.9675903320312\n",
      "Epoch 170/200, Loss: 639.9530029296875\n",
      "Epoch 172/200, Loss: 656.2400512695312\n",
      "Epoch 174/200, Loss: 892.2939453125\n",
      "Epoch 176/200, Loss: 575.2752075195312\n",
      "Epoch 178/200, Loss: 730.7063598632812\n",
      "Epoch 180/200, Loss: 646.810546875\n",
      "Epoch 182/200, Loss: 564.0286254882812\n",
      "Epoch 184/200, Loss: 645.7130737304688\n",
      "Epoch 186/200, Loss: 560.5020751953125\n",
      "Epoch 188/200, Loss: 574.0963745117188\n",
      "Epoch 190/200, Loss: 592.55810546875\n",
      "Epoch 192/200, Loss: 484.5416564941406\n",
      "Epoch 194/200, Loss: 531.2928466796875\n",
      "Epoch 196/200, Loss: 481.1444396972656\n",
      "Epoch 198/200, Loss: 403.5008239746094\n",
      "Epoch 200/200, Loss: 367.5647888183594\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "in_feats = 2  # balanceOrig and balanceDest features\n",
    "hidden_feats = 64\n",
    "out_feats = 1  # Fraud (binary classification)\n",
    "\n",
    "pos_weight = torch.tensor([non_fraud_ratio/fraud_ratio],dtype=torch.float)\n",
    "\n",
    "model = GraphSAGE(in_feats, hidden_feats, out_feats)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    # Forward pass\n",
    "    logits = model(g, g.ndata['features'])\n",
    "    #print(logits.shape)\n",
    "\n",
    "    # Get target labels for the fraud detection task\n",
    "    labels = g.edata['isFraud']\n",
    "    breakpoint()\n",
    "    # Compute loss (use train_mask to filter out test edges)\n",
    "    #print(\"labels\",labels[train_mask].view(-1,1).shape)\n",
    "    #print(\"logits\", logits[train_mask].view(-1,1).shape)\n",
    "    loss = loss_fn(logits[train_mask].view(-1,1), labels[train_mask].view(-1,1))\n",
    "    \n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss every few epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c15695-ca6e-49ef-81e7-b66b7618a1d7",
   "metadata": {},
   "source": [
    "Epoch 2/20, Loss: 50026236.0\n",
    "Epoch 4/20, Loss: 21910472.0\n",
    "Epoch 6/20, Loss: 12671362.0\n",
    "Epoch 8/20, Loss: 12492275.0\n",
    "Epoch 10/20, Loss: 13373789.0\n",
    "Epoch 12/20, Loss: 14267830.0\n",
    "Epoch 14/20, Loss: 14137046.0\n",
    "Epoch 16/20, Loss: 12949893.0\n",
    "Epoch 18/20, Loss: 11810090.0\n",
    "Epoch 20/20, Loss: 10091464.0\n",
    "0.1\n",
    "Accuracy: 0.7332\n",
    "Recall: 0.0086\n",
    "F1 Score: 0.0073\n",
    "0.01\n",
    "Accuracy: 0.7535\n",
    "Recall: 0.0039\n",
    "F1 Score: 0.0036\n",
    "0.2\n",
    "Accuracy: 0.7378\n",
    "Recall: 0.0102\n",
    "F1 Score: 0.0087\n",
    "0.4\n",
    "Accuracy: 0.7405\n",
    "Recall: 0.0079\n",
    "F1 Score: 0.0068"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "23e85df0-9f6b-456d-82b1-b8e41577a6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3674\n",
      "Recall: 0.9560\n",
      "Precision:0.1468\n",
      "F1 Score: 0.2545\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(g, g.ndata['features'])\n",
    "\n",
    "    # Convert logits to probabilities\n",
    "    predictions = torch.sigmoid(logits).squeeze()\n",
    "    \n",
    "    # Apply threshold of 0.5 to classify fraud\n",
    "    predicted_labels = (predictions > 0.).float()\n",
    "    predicted_labels = predicted_labels[test_mask]  # Apply test_mask here\n",
    "    # Get actual labels\n",
    "    #true_labels = g.edata['isFraud']\n",
    "    true_labels = g.edata['isFraud'][test_mask]  # Apply test_mask here\n",
    "    # Compute accuracy manually\n",
    "    correct = (predicted_labels == true_labels).sum().item()\n",
    "    total = true_labels.size(0)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    # Print evaluation results\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    # Calculate F1-Score\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Precision:{precision:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b1c244cd-c6db-48cc-b2b6-56fd33b2d3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.7746])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "207ba890-7fc4-4444-a169-f08dfebd5356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6423)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(labels==1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
