{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2fda4b0-72ce-4e28-9c2a-b9d9248a6615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a sample Python script.\n",
    "import pandas as pd\n",
    "import torch\n",
    "device = torch.device('cpu')\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import dgl.function as fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f18b6091-298f-4e96-933a-64499e87ed3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         step      type     amount     nameOrig  oldbalanceOrg  \\\n",
      "3136595   236  CASH_OUT   81990.42   C770683588           0.00   \n",
      "3603759   263   PAYMENT    3567.16  C1382661261       49225.32   \n",
      "2230134   186  CASH_OUT   97934.16  C1836567111           0.00   \n",
      "290198     15   CASH_IN  106967.79  C1478509364     1933159.03   \n",
      "6161736   550   PAYMENT     975.30   C364317589           0.00   \n",
      "\n",
      "         newbalanceOrig     nameDest  oldbalanceDest  newbalanceDest  isFraud  \\\n",
      "3136595            0.00  C1601899904      1862480.76      1944471.18        0   \n",
      "3603759        45658.16   M869224147            0.00            0.00        0   \n",
      "2230134            0.00   C314667225       288375.89       386310.05        0   \n",
      "290198       2040126.82  C1786291008      1344593.37      1148609.99        0   \n",
      "6161736            0.00   M816906112            0.00            0.00        0   \n",
      "\n",
      "         isFlaggedFraud  \n",
      "3136595               0  \n",
      "3603759               0  \n",
      "2230134               0  \n",
      "290198                0  \n",
      "6161736               0  \n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"../data/PaySim_kaggle.csv\")\n",
    "\n",
    "df=df.sample(n=5000000)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483aa886-0429-41e6-b6d2-120bba8f5c02",
   "metadata": {},
   "source": [
    "Adjust data proportions as the fraud data is heavily biased having less fraudulant cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e65c8bcb-5856-4d91-9eb1-8a090c0b2556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud count: 6473\n",
      "Non-fraud count: 7490\n",
      "Fraud ratio: 0.4636\n",
      "Non-fraud ratio: 0.5364\n"
     ]
    }
   ],
   "source": [
    "# Set the proportion of non-fraud to remove (e.g., 50% of non-fraud instances)\n",
    "remove_fraction = 0.9985\n",
    "\n",
    "# Separate the fraud and non-fraud instances\n",
    "fraud_df = df[df['isFraud'] == 1]\n",
    "non_fraud_df = df[df['isFraud'] == 0]\n",
    "\n",
    "# Randomly sample and remove 'remove_fraction' proportion of non-fraud instances\n",
    "non_fraud_to_remove = non_fraud_df.sample(frac=remove_fraction, random_state=42)\n",
    "\n",
    "# Drop the sampled non-fraud instances from the DataFrame\n",
    "df = df.drop(non_fraud_to_remove.index)\n",
    "\n",
    "# Verify the new balance\n",
    "label_counts = df['isFraud'].value_counts()\n",
    "fraud_ratio = label_counts[1] / len(df)\n",
    "non_fraud_ratio = label_counts[0] / len(df)\n",
    "\n",
    "print(f\"Fraud count: {label_counts[1]}\")\n",
    "print(f\"Non-fraud count: {label_counts[0]}\")\n",
    "print(f\"Fraud ratio: {fraud_ratio:.4f}\")\n",
    "print(f\"Non-fraud ratio: {non_fraud_ratio:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19c68098-4397-40d0-b946-7a0230703f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from unique user names to numeric IDs (nodes)\n",
    "user_mapping = {user: idx for idx, user in enumerate(set(df['nameOrig']).union(set(df['nameDest'])))}\n",
    "\n",
    "# Create edges between nameOrig and nameDest\n",
    "src = df['nameOrig'].map(user_mapping).values\n",
    "dst = df['nameDest'].map(user_mapping).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bfd81d5-b2e8-4941-bc11-f3bd4257dcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4399  1489  6576 ... 19390 10962 23283]\n"
     ]
    }
   ],
   "source": [
    "print(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5253dc18-6c5e-4523-ab68-d45b6984bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DGL graph from the source and destination nodes\n",
    "g = dgl.graph((src, dst))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8d8d10c-4b83-4564-a4d1-280fae10d4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add transaction amount as edge feature\n",
    "g.edata['amount'] = torch.tensor(df['amount'].values, dtype=torch.float32)\n",
    "\n",
    "# Optional: Add fraud information to edge features\n",
    "g.edata['isFraud'] = torch.tensor(df['isFraud'].values, dtype=torch.float32)\n",
    "\n",
    "# Initialize node features with zeros (this handles all nodes)\n",
    "num_nodes = g.num_nodes()\n",
    "balance_orig = torch.zeros(num_nodes, dtype=torch.float32)\n",
    "balance_dest = torch.zeros(num_nodes, dtype=torch.float32)\n",
    "\n",
    "# Average balance for each origin user (nameOrig)\n",
    "for orig_user, balance in df.groupby('nameOrig')['oldbalanceOrg'].mean().items():\n",
    "    balance_orig[user_mapping[orig_user]] = balance\n",
    "\n",
    "# Average balance for each destination user (nameDest)\n",
    "for dest_user, balance in df.groupby('nameDest')['oldbalanceDest'].mean().items():\n",
    "    balance_dest[user_mapping[dest_user]] = balance\n",
    "\n",
    "node_features = torch.stack([balance_orig, balance_dest], dim=1)  # Changed to stack both features\n",
    "\n",
    "g.ndata['features'] = node_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e37e5f8-5d2f-492e-8fcc-db40ce4f3e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DGLGraph.num_edges of Graph(num_nodes=27808, num_edges=13963,\n",
       "      ndata_schemes={'features': Scheme(shape=(2,), dtype=torch.float32)}\n",
       "      edata_schemes={'amount': Scheme(shape=(), dtype=torch.float32), 'isFraud': Scheme(shape=(), dtype=torch.float32)})>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edata['isFraud'].shape\n",
    "#node_features.shape\n",
    "g.num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "788366e2-8e69-40f7-82d7-5bb92f9a1ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print graph information\n",
    "#print(g)\n",
    "\n",
    "# Visualize the graph using NetworkX (convert DGL graph to NetworkX for visualization)\n",
    "#nx_graph = g.to_networkx()\n",
    "\n",
    "# Optional: Visualize using a layout for better readability\n",
    "#pos = nx.spring_layout(nx_graph)  # Use a layout for better visualization\n",
    "#plt.figure(figsize=(12, 12))\n",
    "#nx.draw(nx_graph, pos, node_size=50, node_color='skyblue', font_size=10, with_labels=True)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe561538-118f-4c17-b6cc-54460d44f063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge Features (Transaction Amounts):\n",
      "tensor([4.4701e+05, 7.1600e+01, 1.0000e+07,  ..., 4.6238e+06, 9.8904e+04,\n",
      "        1.4662e+04])\n"
     ]
    }
   ],
   "source": [
    "# Assuming that you have edge features like transaction amounts or fraud status\n",
    "edge_features = g.edata.get('amount', None)  # Assuming 'amount' is an edge feature\n",
    "if edge_features is not None:\n",
    "    print(\"Edge Features (Transaction Amounts):\")\n",
    "    print(edge_features)\n",
    "else:\n",
    "    print(\"No edge features found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecd2e705-81a6-4e96-a46a-7e8af83ea77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = g.edges()\n",
    "# Split the dataset into train and test set\n",
    "# Generate indices for train-test split (80% train, 20% test)\n",
    "num_train_edges = int(0.8 * len(edges[0]))\n",
    "train_indices = torch.arange(num_train_edges)\n",
    "test_indices = torch.arange(num_train_edges, len(edges[0]))\n",
    "\n",
    "# Create masks for training and testing\n",
    "train_mask = torch.zeros(len(edges[0]), dtype=torch.bool)\n",
    "test_mask = torch.zeros(len(edges[0]), dtype=torch.bool)\n",
    "train_mask[train_indices] = 1\n",
    "test_mask[test_indices] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b521fd7-bdfd-47eb-a894-4f4175fd2ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GraphSAGE model for fraud detection\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_feats, out_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.layer1 = dgl.nn.SAGEConv(in_feats, hidden_feats, 'mean')\n",
    "        self.layer2 = dgl.nn.SAGEConv(hidden_feats, out_feats, 'mean')\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(out_feats * 2, 1)  # * Concatenate source and destination node embeddings *\n",
    "        \n",
    "    def forward(self, g, features):\n",
    "        # Apply first GraphSAGE layer and ReLU\n",
    "        x = self.layer1(g, features)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Apply second GraphSAGE layer to get embeddings\n",
    "        x = self.layer2(g, x)\n",
    "        \n",
    "        # Get source and destination nodes for each edge\n",
    "        src, dst = g.edges()  # Get indices of source and destination nodes\n",
    "        src_embeddings = x[src]  # Embeddings for source nodes\n",
    "        dst_embeddings = x[dst]  # Embeddings for destination nodes\n",
    "        \n",
    "        # Concatenate source and destination node embeddings to create edge features\n",
    "        edge_features = torch.cat([src_embeddings, dst_embeddings], dim=1)  # Concatenate along the feature dimension\n",
    "        logits = self.fc(edge_features).squeeze()  # * Output a single value per edge (fraud score) *\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "caf5f966-4635-469e-a2d6-2bf70d46c371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud count: 6473\n",
      "Non-fraud count: 7490\n",
      "Fraud ratio: 0.4636\n",
      "Non-fraud ratio: 0.5364\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each label in the 'isFraud' column\n",
    "label_counts = df['isFraud'].value_counts()\n",
    "\n",
    "# Calculate the proportion of each class\n",
    "fraud_ratio = label_counts[1] / len(df)  # Assuming '1' represents fraud\n",
    "non_fraud_ratio = label_counts[0] / len(df)  # Assuming '0' represents non-fraud\n",
    "\n",
    "# Print the results\n",
    "print(f\"Fraud count: {label_counts[1]}\")\n",
    "print(f\"Non-fraud count: {label_counts[0]}\")\n",
    "print(f\"Fraud ratio: {fraud_ratio:.4f}\")\n",
    "print(f\"Non-fraud ratio: {non_fraud_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f542233-e155-4918-8816-b1e3e427d999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200, Loss: 181141.859375\n",
      "Epoch 4/200, Loss: 157430.96875\n",
      "Epoch 6/200, Loss: 141447.1875\n",
      "Epoch 8/200, Loss: 124156.8125\n",
      "Epoch 10/200, Loss: 105468.703125\n",
      "Epoch 12/200, Loss: 104094.1171875\n",
      "Epoch 14/200, Loss: 91447.046875\n",
      "Epoch 16/200, Loss: 83232.3984375\n",
      "Epoch 18/200, Loss: 77547.59375\n",
      "Epoch 20/200, Loss: 70832.34375\n",
      "Epoch 22/200, Loss: 64617.90625\n",
      "Epoch 24/200, Loss: 57601.42578125\n",
      "Epoch 26/200, Loss: 52511.15625\n",
      "Epoch 28/200, Loss: 48590.59375\n",
      "Epoch 30/200, Loss: 41939.39453125\n",
      "Epoch 32/200, Loss: 41129.41796875\n",
      "Epoch 34/200, Loss: 34319.625\n",
      "Epoch 36/200, Loss: 33910.08984375\n",
      "Epoch 38/200, Loss: 30555.84375\n",
      "Epoch 40/200, Loss: 27881.60546875\n",
      "Epoch 42/200, Loss: 24897.859375\n",
      "Epoch 44/200, Loss: 23411.298828125\n",
      "Epoch 46/200, Loss: 21357.138671875\n",
      "Epoch 48/200, Loss: 19342.193359375\n",
      "Epoch 50/200, Loss: 17413.33203125\n",
      "Epoch 52/200, Loss: 16113.263671875\n",
      "Epoch 54/200, Loss: 15382.1494140625\n",
      "Epoch 56/200, Loss: 13575.458984375\n",
      "Epoch 58/200, Loss: 12372.8271484375\n",
      "Epoch 60/200, Loss: 11697.7724609375\n",
      "Epoch 62/200, Loss: 10138.9482421875\n",
      "Epoch 64/200, Loss: 9055.0595703125\n",
      "Epoch 66/200, Loss: 8783.1875\n",
      "Epoch 68/200, Loss: 8183.13916015625\n",
      "Epoch 70/200, Loss: 8353.384765625\n",
      "Epoch 72/200, Loss: 7730.3232421875\n",
      "Epoch 74/200, Loss: 6648.92333984375\n",
      "Epoch 76/200, Loss: 6326.25830078125\n",
      "Epoch 78/200, Loss: 5280.32421875\n",
      "Epoch 80/200, Loss: 5184.90283203125\n",
      "Epoch 82/200, Loss: 4923.5078125\n",
      "Epoch 84/200, Loss: 4881.94677734375\n",
      "Epoch 86/200, Loss: 4371.4599609375\n",
      "Epoch 88/200, Loss: 4170.62744140625\n",
      "Epoch 90/200, Loss: 3626.57666015625\n",
      "Epoch 92/200, Loss: 3581.1337890625\n",
      "Epoch 94/200, Loss: 3221.10791015625\n",
      "Epoch 96/200, Loss: 3320.202392578125\n",
      "Epoch 98/200, Loss: 3042.522216796875\n",
      "Epoch 100/200, Loss: 2828.05810546875\n",
      "Epoch 102/200, Loss: 2664.911865234375\n",
      "Epoch 104/200, Loss: 2317.0263671875\n",
      "Epoch 106/200, Loss: 2116.21923828125\n",
      "Epoch 108/200, Loss: 2140.294189453125\n",
      "Epoch 110/200, Loss: 1979.11474609375\n",
      "Epoch 112/200, Loss: 1934.0145263671875\n",
      "Epoch 114/200, Loss: 1858.76953125\n",
      "Epoch 116/200, Loss: 1629.378662109375\n",
      "Epoch 118/200, Loss: 1685.91748046875\n",
      "Epoch 120/200, Loss: 1451.5634765625\n",
      "Epoch 122/200, Loss: 1413.0858154296875\n",
      "Epoch 124/200, Loss: 1294.4991455078125\n",
      "Epoch 126/200, Loss: 1367.78857421875\n",
      "Epoch 128/200, Loss: 1213.4420166015625\n",
      "Epoch 130/200, Loss: 1233.816162109375\n",
      "Epoch 132/200, Loss: 1046.7027587890625\n",
      "Epoch 134/200, Loss: 987.4568481445312\n",
      "Epoch 136/200, Loss: 968.9198608398438\n",
      "Epoch 138/200, Loss: 908.4622192382812\n",
      "Epoch 140/200, Loss: 1202.9111328125\n",
      "Epoch 142/200, Loss: 1080.051025390625\n",
      "Epoch 144/200, Loss: 829.2616577148438\n",
      "Epoch 146/200, Loss: 761.1945190429688\n",
      "Epoch 148/200, Loss: 886.5803833007812\n",
      "Epoch 150/200, Loss: 742.1422729492188\n",
      "Epoch 152/200, Loss: 587.3034057617188\n",
      "Epoch 154/200, Loss: 695.95068359375\n",
      "Epoch 156/200, Loss: 625.119140625\n",
      "Epoch 158/200, Loss: 575.00244140625\n",
      "Epoch 160/200, Loss: 520.3890991210938\n",
      "Epoch 162/200, Loss: 507.3434753417969\n",
      "Epoch 164/200, Loss: 543.5127563476562\n",
      "Epoch 166/200, Loss: 488.47216796875\n",
      "Epoch 168/200, Loss: 430.2951354980469\n",
      "Epoch 170/200, Loss: 392.5766296386719\n",
      "Epoch 172/200, Loss: 387.5746154785156\n",
      "Epoch 174/200, Loss: 365.5046691894531\n",
      "Epoch 176/200, Loss: 306.07806396484375\n",
      "Epoch 178/200, Loss: 518.4441528320312\n",
      "Epoch 180/200, Loss: 388.1748352050781\n",
      "Epoch 182/200, Loss: 340.6708068847656\n",
      "Epoch 184/200, Loss: 356.6206970214844\n",
      "Epoch 186/200, Loss: 337.70220947265625\n",
      "Epoch 188/200, Loss: 295.6641845703125\n",
      "Epoch 190/200, Loss: 301.05169677734375\n",
      "Epoch 192/200, Loss: 264.41522216796875\n",
      "Epoch 194/200, Loss: 233.13990783691406\n",
      "Epoch 196/200, Loss: 244.89768981933594\n",
      "Epoch 198/200, Loss: 186.35206604003906\n",
      "Epoch 200/200, Loss: 171.3194122314453\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "in_feats = 2  # balanceOrig and balanceDest features\n",
    "hidden_feats = 64\n",
    "out_feats = 1  # Fraud (binary classification)\n",
    "\n",
    "pos_weight = torch.tensor([non_fraud_ratio/fraud_ratio],dtype=torch.float)\n",
    "#pos_weight = torch.tensor([1.0],dtype=torch.float)\n",
    "\n",
    "model = GraphSAGE(in_feats, hidden_feats, out_feats)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "# Train the model\n",
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    # Forward pass\n",
    "    logits = model(g, g.ndata['features'])\n",
    "    #print(logits.shape)\n",
    "\n",
    "    # Get target labels for the fraud detection task\n",
    "    labels = g.edata['isFraud']\n",
    "    breakpoint()\n",
    "    # Compute loss (use train_mask to filter out test edges)\n",
    "    #print(\"labels\",labels[train_mask].view(-1,1).shape)\n",
    "    #print(\"logits\", logits[train_mask].view(-1,1).shape)\n",
    "    loss = loss_fn(logits[train_mask].view(-1,1), labels[train_mask].view(-1,1))\n",
    "    \n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss every few epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c15695-ca6e-49ef-81e7-b66b7618a1d7",
   "metadata": {},
   "source": [
    "Epoch 2/20, Loss: 50026236.0\n",
    "Epoch 4/20, Loss: 21910472.0\n",
    "Epoch 6/20, Loss: 12671362.0\n",
    "Epoch 8/20, Loss: 12492275.0\n",
    "Epoch 10/20, Loss: 13373789.0\n",
    "Epoch 12/20, Loss: 14267830.0\n",
    "Epoch 14/20, Loss: 14137046.0\n",
    "Epoch 16/20, Loss: 12949893.0\n",
    "Epoch 18/20, Loss: 11810090.0\n",
    "Epoch 20/20, Loss: 10091464.0\n",
    "0.1\n",
    "Accuracy: 0.7332\n",
    "Recall: 0.0086\n",
    "F1 Score: 0.0073\n",
    "0.01\n",
    "Accuracy: 0.7535\n",
    "Recall: 0.0039\n",
    "F1 Score: 0.0036\n",
    "0.2\n",
    "Accuracy: 0.7378\n",
    "Recall: 0.0102\n",
    "F1 Score: 0.0087\n",
    "0.4\n",
    "Accuracy: 0.7405\n",
    "Recall: 0.0079\n",
    "F1 Score: 0.0068"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23e85df0-9f6b-456d-82b1-b8e41577a6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7075\n",
      "Recall: 0.6301\n",
      "Precision:0.7071\n",
      "F1 Score: 0.6664\n",
      "{'orig_user': 'C1715567191', 'dest_user': 'C688227079', 'predicted_label': 0, 'true_label': 0, 'balance_orig': 26673.0, 'balance_dest': 9131827.0}\n",
      "{'orig_user': 'C384906661', 'dest_user': 'C244625639', 'predicted_label': 0, 'true_label': 0, 'balance_orig': 0.0, 'balance_dest': 3202547.75}\n",
      "{'orig_user': 'C1050766872', 'dest_user': 'C1332247082', 'predicted_label': 0, 'true_label': 0, 'balance_orig': 10068.0, 'balance_dest': 115406.921875}\n",
      "{'orig_user': 'C71055143', 'dest_user': 'C1732817669', 'predicted_label': 0, 'true_label': 1, 'balance_orig': 271908.40625, 'balance_dest': 1488088.25}\n",
      "{'orig_user': 'C744241593', 'dest_user': 'M967615944', 'predicted_label': 0, 'true_label': 0, 'balance_orig': 0.0, 'balance_dest': 0.0}\n",
      "{'orig_user': 'C294569503', 'dest_user': 'C229133194', 'predicted_label': 1, 'true_label': 1, 'balance_orig': 3309631.0, 'balance_dest': 0.0}\n",
      "{'orig_user': 'C1223797124', 'dest_user': 'C1631519993', 'predicted_label': 1, 'true_label': 1, 'balance_orig': 329424.125, 'balance_dest': 0.0}\n",
      "{'orig_user': 'C1447355548', 'dest_user': 'C110798588', 'predicted_label': 1, 'true_label': 1, 'balance_orig': 3178881.75, 'balance_dest': 0.0}\n",
      "{'orig_user': 'C1799853230', 'dest_user': 'C1294375494', 'predicted_label': 0, 'true_label': 0, 'balance_orig': 507806.65625, 'balance_dest': 176472.8125}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(g, g.ndata['features'])\n",
    "\n",
    "    # Convert logits to probabilities\n",
    "    predictions = torch.sigmoid(logits).squeeze()\n",
    "    \n",
    "    # Apply threshold of 0.5 to classify fraud\n",
    "    predicted_labels = (predictions > 0.5).float()\n",
    "    predicted_labels = predicted_labels[test_mask]  # Apply test_mask here\n",
    "    # Get actual labels\n",
    "    #true_labels = g.edata['isFraud']\n",
    "    true_labels = g.edata['isFraud'][test_mask]  # Apply test_mask here\n",
    "\n",
    "    reverse_user_mapping = {v: k for k, v in user_mapping.items()}  # Reverse mapping\n",
    "    \n",
    "    # Retrieve node indices from test_mask\n",
    "    #test_edge_indices = test_mask.nonzero().squeeze().tolist()\n",
    "    src, dst = g.edges()\n",
    "    src_test = src[test_mask]\n",
    "    dst_test = dst[test_mask]\n",
    "        \n",
    "    balance_orig_test = g.ndata['features'][src_test, 0].tolist()\n",
    "    balance_dest_test = g.ndata['features'][dst_test, 1].tolist()\n",
    "    \n",
    "    # Map predictions back to transactions with their original balances\n",
    "    mapped_results = [\n",
    "        {\n",
    "            \"orig_user\": reverse_user_mapping[src_node.item()],\n",
    "            \"dest_user\": reverse_user_mapping[dst_node.item()],\n",
    "            \"predicted_label\": int(pred),\n",
    "            \"true_label\": int(true_lab),\n",
    "            \"balance_orig\": balance_orig,\n",
    "            \"balance_dest\": balance_dest\n",
    "        }\n",
    "        for src_node, dst_node, pred, true_lab, balance_orig, balance_dest in zip(\n",
    "            src_test, dst_test, predicted_labels.tolist(), true_labels.tolist(), balance_orig_test, balance_dest_test\n",
    "        )\n",
    "    ]\n",
    "    # Compute accuracy manually\n",
    "    correct = (predicted_labels == true_labels).sum().item()\n",
    "    total = true_labels.size(0)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    # Print evaluation results\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    # Calculate F1-Score\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Precision:{precision:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    for result in mapped_results[1:10]:\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1c244cd-c6db-48cc-b2b6-56fd33b2d3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7793])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "207ba890-7fc4-4444-a169-f08dfebd5356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6408)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(labels==1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
