{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2fda4b0-72ce-4e28-9c2a-b9d9248a6615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a sample Python script.\n",
    "import pandas as pd\n",
    "import torch\n",
    "device = torch.device('cpu')\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import dgl.function as fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f18b6091-298f-4e96-933a-64499e87ed3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         step      type     amount     nameOrig  oldbalanceOrg  \\\n",
      "3637253   274   PAYMENT    7373.21   C881990608            0.0   \n",
      "998398     45   PAYMENT    5640.53  C1286376759        32615.0   \n",
      "1708338   160  TRANSFER  187660.37  C1888545418        10920.0   \n",
      "2206533   186   PAYMENT    2565.17  C1626154761            0.0   \n",
      "3206054   249  CASH_OUT  353256.96  C2012861900          473.0   \n",
      "\n",
      "         newbalanceOrig     nameDest  oldbalanceDest  newbalanceDest  isFraud  \\\n",
      "3637253            0.00   M767846099             0.0            0.00        0   \n",
      "998398         26974.47  M1564171620             0.0            0.00        0   \n",
      "1708338            0.00  C1458605482             0.0       187660.37        0   \n",
      "2206533            0.00   M761403458             0.0            0.00        0   \n",
      "3206054            0.00  C1063995645             0.0       353256.96        0   \n",
      "\n",
      "         isFlaggedFraud  \n",
      "3637253               0  \n",
      "998398                0  \n",
      "1708338               0  \n",
      "2206533               0  \n",
      "3206054               0  \n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"../data/PaySim_kaggle.csv\")\n",
    "\n",
    "df=df.sample(n=5000000)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e65c8bcb-5856-4d91-9eb1-8a090c0b2556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud count: 6409\n",
      "Non-fraud count: 49936\n",
      "Fraud ratio: 0.1137\n",
      "Non-fraud ratio: 0.8863\n"
     ]
    }
   ],
   "source": [
    "# Set the proportion of non-fraud to remove (e.g., 50% of non-fraud instances)\n",
    "remove_fraction = 0.99\n",
    "\n",
    "# Separate the fraud and non-fraud instances\n",
    "fraud_df = df[df['isFraud'] == 1]\n",
    "non_fraud_df = df[df['isFraud'] == 0]\n",
    "\n",
    "# Randomly sample and remove 'remove_fraction' proportion of non-fraud instances\n",
    "non_fraud_to_remove = non_fraud_df.sample(frac=remove_fraction, random_state=42)\n",
    "\n",
    "# Drop the sampled non-fraud instances from the DataFrame\n",
    "df = df.drop(non_fraud_to_remove.index)\n",
    "\n",
    "# Verify the new balance\n",
    "label_counts = df['isFraud'].value_counts()\n",
    "fraud_ratio = label_counts[1] / len(df)\n",
    "non_fraud_ratio = label_counts[0] / len(df)\n",
    "\n",
    "print(f\"Fraud count: {label_counts[1]}\")\n",
    "print(f\"Non-fraud count: {label_counts[0]}\")\n",
    "print(f\"Fraud ratio: {fraud_ratio:.4f}\")\n",
    "print(f\"Non-fraud ratio: {non_fraud_ratio:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19c68098-4397-40d0-b946-7a0230703f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from unique user names to numeric IDs (nodes)\n",
    "user_mapping = {user: idx for idx, user in enumerate(set(df['nameOrig']).union(set(df['nameDest'])))}\n",
    "\n",
    "# Create edges between nameOrig and nameDest\n",
    "src = df['nameOrig'].map(user_mapping).values\n",
    "dst = df['nameDest'].map(user_mapping).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bfd81d5-b2e8-4941-bc11-f3bd4257dcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 98951  16608  43525 ... 109646  39258  29190]\n"
     ]
    }
   ],
   "source": [
    "print(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5253dc18-6c5e-4523-ab68-d45b6984bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DGL graph from the source and destination nodes\n",
    "g = dgl.graph((src, dst))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8d8d10c-4b83-4564-a4d1-280fae10d4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add transaction amount as edge feature\n",
    "g.edata['amount'] = torch.tensor(df['amount'].values, dtype=torch.float32)\n",
    "\n",
    "# Optional: Add fraud information to edge features\n",
    "g.edata['isFraud'] = torch.tensor(df['isFraud'].values, dtype=torch.float32)\n",
    "\n",
    "# Initialize node features with zeros (this handles all nodes)\n",
    "num_nodes = g.num_nodes()\n",
    "balance_orig = torch.zeros(num_nodes, dtype=torch.float32)\n",
    "balance_dest = torch.zeros(num_nodes, dtype=torch.float32)\n",
    "\n",
    "for orig_user, balance in df[['nameOrig', 'oldbalanceOrg']].drop_duplicates().values:\n",
    "    balance_orig[user_mapping[orig_user]] = balance\n",
    "\n",
    "for dest_user, balance in df[['nameDest', 'oldbalanceDest']].drop_duplicates().values:\n",
    "    balance_dest[user_mapping[dest_user]] = balance\n",
    "\n",
    "node_features = torch.stack([balance_orig, balance_dest], dim=1)  # Changed to stack both features\n",
    "\n",
    "g.ndata['features'] = node_features\n",
    "\n",
    "node_labels = torch.zeros(num_nodes, dtype=torch.float32)\n",
    "\n",
    "# Map 'isFraud' values to corresponding nodes based on user mapping\n",
    "for user, fraud in df[['nameOrig', 'isFraud']].drop_duplicates().values:\n",
    "    node_labels[user_mapping[user]] = fraud\n",
    "\n",
    "\n",
    "# Map 'isFraud' to destination nodes (nameDest)\n",
    "for dest_user, fraud in df[['nameDest', 'isFraud']].drop_duplicates().values:\n",
    "    node_labels[user_mapping[dest_user]] = fraud\n",
    "\n",
    "# Store the fraud labels in g.ndata['isFraud']\n",
    "g.ndata['isFraud'] = node_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e37e5f8-5d2f-492e-8fcc-db40ce4f3e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DGLGraph.num_edges of Graph(num_nodes=110511, num_edges=56345,\n",
       "      ndata_schemes={'features': Scheme(shape=(2,), dtype=torch.float32), 'isFraud': Scheme(shape=(), dtype=torch.float32)}\n",
       "      edata_schemes={'amount': Scheme(shape=(), dtype=torch.float32), 'isFraud': Scheme(shape=(), dtype=torch.float32)})>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edata['isFraud'].shape\n",
    "#node_features.shape\n",
    "g.num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "788366e2-8e69-40f7-82d7-5bb92f9a1ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print graph information\n",
    "#print(g)\n",
    "\n",
    "# Visualize the graph using NetworkX (convert DGL graph to NetworkX for visualization)\n",
    "#nx_graph = g.to_networkx()\n",
    "\n",
    "# Optional: Visualize using a layout for better readability\n",
    "#pos = nx.spring_layout(nx_graph)  # Use a layout for better visualization\n",
    "#plt.figure(figsize=(12, 12))\n",
    "#nx.draw(nx_graph, pos, node_size=50, node_color='skyblue', font_size=10, with_labels=True)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe561538-118f-4c17-b6cc-54460d44f063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge Features (Transaction Amounts):\n",
      "tensor([211672.7031,   2996.7200,  27319.2207,  ..., 179439.6719,\n",
      "          3330.6799,  29678.9805])\n"
     ]
    }
   ],
   "source": [
    "# Assuming that you have edge features like transaction amounts or fraud status\n",
    "edge_features = g.edata.get('amount', None)  # Assuming 'amount' is an edge feature\n",
    "if edge_features is not None:\n",
    "    print(\"Edge Features (Transaction Amounts):\")\n",
    "    print(edge_features)\n",
    "else:\n",
    "    print(\"No edge features found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecd2e705-81a6-4e96-a46a-7e8af83ea77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 80% of nodes for training\n",
    "num_train_nodes = int(0.8 * num_nodes)\n",
    "train_indices = torch.randperm(num_nodes)[:num_train_nodes]  \n",
    "test_indices = torch.tensor([i for i in range(num_nodes) if i not in train_indices])\n",
    "\n",
    "# Create train/test masks\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "train_mask[train_indices] = True\n",
    "test_mask[test_indices] = True\n",
    "\n",
    "# Assign to graph\n",
    "g.ndata['train_mask'] = train_mask\n",
    "g.ndata['test_mask'] = test_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b521fd7-bdfd-47eb-a894-4f4175fd2ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GraphSAGE model for fraud detection\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_feats, out_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.layer1 = dgl.nn.SAGEConv(in_feats, hidden_feats, 'mean')\n",
    "        self.layer2 = dgl.nn.SAGEConv(hidden_feats, out_feats, 'mean')\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        #self.fc = nn.Linear(out_feats * 2, 1)  # * Concatenate source and destination node embeddings *\n",
    "        self.fc = nn.Linear(out_feats, 1)  # Output a single value per node (fraud score)\n",
    "        \n",
    "    def forward(self, g, features):\n",
    "        # Apply first GraphSAGE layer and ReLU\n",
    "        x = self.layer1(g, features)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Apply second GraphSAGE layer to get node embeddings\n",
    "        x = self.layer2(g, x)\n",
    "        \n",
    "        # Output a prediction for each node\n",
    "        logits = self.fc(x).squeeze()  # Output a single value per node\n",
    "        return logits\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caf5f966-4635-469e-a2d6-2bf70d46c371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud count: 6409\n",
      "Non-fraud count: 49936\n",
      "Fraud ratio: 0.1137\n",
      "Non-fraud ratio: 0.8863\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each label in the 'isFraud' column\n",
    "label_counts = df['isFraud'].value_counts()\n",
    "\n",
    "# Calculate the proportion of each class\n",
    "fraud_ratio = label_counts[1] / len(df)  # Assuming '1' represents fraud\n",
    "non_fraud_ratio = label_counts[0] / len(df)  # Assuming '0' represents non-fraud\n",
    "\n",
    "# Print the results\n",
    "print(f\"Fraud count: {label_counts[1]}\")\n",
    "print(f\"Non-fraud count: {label_counts[0]}\")\n",
    "print(f\"Fraud ratio: {fraud_ratio:.4f}\")\n",
    "print(f\"Non-fraud ratio: {non_fraud_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f542233-e155-4918-8816-b1e3e427d999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100, Loss: 44732.2421875\n",
      "Epoch 4/100, Loss: 28791.125\n",
      "Epoch 6/100, Loss: 22544.580078125\n",
      "Epoch 8/100, Loss: 16632.666015625\n",
      "Epoch 10/100, Loss: 8951.3779296875\n",
      "Epoch 12/100, Loss: 2283.446044921875\n",
      "Epoch 14/100, Loss: 5016.560546875\n",
      "Epoch 16/100, Loss: 6326.47314453125\n",
      "Epoch 18/100, Loss: 4026.737060546875\n",
      "Epoch 20/100, Loss: 314.09515380859375\n",
      "Epoch 22/100, Loss: 2020.7969970703125\n",
      "Epoch 24/100, Loss: 3303.24072265625\n",
      "Epoch 26/100, Loss: 3292.263427734375\n",
      "Epoch 28/100, Loss: 2442.7509765625\n",
      "Epoch 30/100, Loss: 1223.515380859375\n",
      "Epoch 32/100, Loss: 246.31993103027344\n",
      "Epoch 34/100, Loss: 1165.792236328125\n",
      "Epoch 36/100, Loss: 1140.3226318359375\n",
      "Epoch 38/100, Loss: 343.8805236816406\n",
      "Epoch 40/100, Loss: 522.3054809570312\n",
      "Epoch 42/100, Loss: 696.5490112304688\n",
      "Epoch 44/100, Loss: 395.1559143066406\n",
      "Epoch 46/100, Loss: 388.766845703125\n",
      "Epoch 48/100, Loss: 692.5899658203125\n",
      "Epoch 50/100, Loss: 191.53501892089844\n",
      "Epoch 52/100, Loss: 447.5279541015625\n",
      "Epoch 54/100, Loss: 523.6150512695312\n",
      "Epoch 56/100, Loss: 60.74388122558594\n",
      "Epoch 58/100, Loss: 595.3917236328125\n",
      "Epoch 60/100, Loss: 487.1595458984375\n",
      "Epoch 62/100, Loss: 247.65557861328125\n",
      "Epoch 64/100, Loss: 513.32666015625\n",
      "Epoch 66/100, Loss: 295.6311340332031\n",
      "Epoch 68/100, Loss: 408.3406982421875\n",
      "Epoch 70/100, Loss: 657.3978881835938\n",
      "Epoch 72/100, Loss: 292.0806579589844\n",
      "Epoch 74/100, Loss: 278.5245666503906\n",
      "Epoch 76/100, Loss: 223.07321166992188\n",
      "Epoch 78/100, Loss: 79.04917907714844\n",
      "Epoch 80/100, Loss: 179.27061462402344\n",
      "Epoch 82/100, Loss: 149.07765197753906\n",
      "Epoch 84/100, Loss: 118.90474700927734\n",
      "Epoch 86/100, Loss: 185.9506378173828\n",
      "Epoch 88/100, Loss: 164.602294921875\n",
      "Epoch 90/100, Loss: 75.21414184570312\n",
      "Epoch 92/100, Loss: 10.538578987121582\n",
      "Epoch 94/100, Loss: 51.22239685058594\n",
      "Epoch 96/100, Loss: 116.29884338378906\n",
      "Epoch 98/100, Loss: 41.61237716674805\n",
      "Epoch 100/100, Loss: 81.1961441040039\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "in_feats = 2  # balanceOrig and balanceDest features\n",
    "hidden_feats = 64\n",
    "out_feats = 1  # Fraud (binary classification)\n",
    "\n",
    "pos_weight = torch.tensor([non_fraud_ratio/fraud_ratio],dtype=torch.float)\n",
    "\n",
    "model = GraphSAGE(in_feats, hidden_feats, out_feats)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    # Forward pass\n",
    "    logits = model(g, g.ndata['features'])\n",
    "    #print(logits.shape)\n",
    "\n",
    "    # Get target labels for the fraud detection task\n",
    "    labels = g.ndata['isFraud']\n",
    "    breakpoint()\n",
    "    # Compute loss (use train_mask to filter out test edges)\n",
    "    #print(\"labels\",labels[train_mask].view(-1,1).shape)\n",
    "    #print(\"logits\", logits[train_mask].view(-1,1).shape)\n",
    "    loss = loss_fn(logits[train_mask].view(-1,1), labels[train_mask].view(-1,1))\n",
    "    \n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss every few epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c15695-ca6e-49ef-81e7-b66b7618a1d7",
   "metadata": {},
   "source": [
    "Epoch 2/20, Loss: 50026236.0\n",
    "Epoch 4/20, Loss: 21910472.0\n",
    "Epoch 6/20, Loss: 12671362.0\n",
    "Epoch 8/20, Loss: 12492275.0\n",
    "Epoch 10/20, Loss: 13373789.0\n",
    "Epoch 12/20, Loss: 14267830.0\n",
    "Epoch 14/20, Loss: 14137046.0\n",
    "Epoch 16/20, Loss: 12949893.0\n",
    "Epoch 18/20, Loss: 11810090.0\n",
    "Epoch 20/20, Loss: 10091464.0\n",
    "0.1\n",
    "Accuracy: 0.7332\n",
    "Recall: 0.0086\n",
    "F1 Score: 0.0073\n",
    "0.01\n",
    "Accuracy: 0.7535\n",
    "Recall: 0.0039\n",
    "F1 Score: 0.0036\n",
    "0.2\n",
    "Accuracy: 0.7378\n",
    "Recall: 0.0102\n",
    "F1 Score: 0.0087\n",
    "0.4\n",
    "Accuracy: 0.7405\n",
    "Recall: 0.0079\n",
    "F1 Score: 0.0068"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d073edc-243e-4b6e-9d3e-9ac7d47ce144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['features', 'isFraud', 'train_mask', 'test_mask'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.ndata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23e85df0-9f6b-456d-82b1-b8e41577a6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6761\n",
      "Recall: 0.3880\n",
      "Precision:0.1475\n",
      "F1 Score: 0.2137\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(g, g.ndata['features'])\n",
    "\n",
    "    # Convert logits to probabilities\n",
    "    predictions = torch.sigmoid(logits).squeeze()\n",
    "    \n",
    "    # Apply threshold of 0.5 to classify fraud\n",
    "    predicted_labels = (predictions > 0.5).float()\n",
    "    predicted_labels = predicted_labels[test_mask]  # Apply test_mask here\n",
    "    # Get actual labels\n",
    "    #true_labels = g.edata['isFraud']\n",
    "    true_labels = g.ndata['isFraud'][test_mask]  # Apply test_mask here\n",
    "    # Compute accuracy manually\n",
    "    correct = (predicted_labels == true_labels).sum().item()\n",
    "    total = true_labels.size(0)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    # Print evaluation results\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    # Calculate F1-Score\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Precision:{precision:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1c244cd-c6db-48cc-b2b6-56fd33b2d3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.,  ..., 0., 1., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.ndata['features']\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "207ba890-7fc4-4444-a169-f08dfebd5356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12639)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(labels==1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
