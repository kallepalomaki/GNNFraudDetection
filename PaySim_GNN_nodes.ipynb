{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2fda4b0-72ce-4e28-9c2a-b9d9248a6615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a sample Python script.\n",
    "import pandas as pd\n",
    "import torch\n",
    "device = torch.device('cpu')\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import dgl.function as fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f18b6091-298f-4e96-933a-64499e87ed3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../data/PaySim_kaggle.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497df701-9ae7-49b5-8e86-daa20fb723d4",
   "metadata": {},
   "source": [
    "Adjust data proportions as the fraud data is heavily biased having less fraudulant cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e65c8bcb-5856-4d91-9eb1-8a090c0b2556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud count: 8213\n",
      "Non-fraud count: 9532\n",
      "Fraud ratio: 0.4628\n",
      "Non-fraud ratio: 0.5372\n",
      "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
      "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
      "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
      "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
      "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
      "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
      "\n",
      "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
      "0  M1979787155             0.0             0.0        0               0  \n",
      "1  M2044282225             0.0             0.0        0               0  \n",
      "2   C553264065             0.0             0.0        1               0  \n",
      "3    C38997010         21182.0             0.0        1               0  \n",
      "4  M1230701703             0.0             0.0        0               0  \n"
     ]
    }
   ],
   "source": [
    "# Set the proportion of non-fraud to remove (e.g., 50% of non-fraud instances)\n",
    "remove_fraction = 0.9985\n",
    "\n",
    "# Separate the fraud and non-fraud instances\n",
    "fraud_df = df[df['isFraud'] == 1]\n",
    "non_fraud_df = df[df['isFraud'] == 0]\n",
    "\n",
    "# Randomly sample and remove 'remove_fraction' proportion of non-fraud instances\n",
    "# Calculate the number of rows to remove based on the fraction\n",
    "rows_to_remove = int(len(non_fraud_df) * remove_fraction)\n",
    "\n",
    "# Select the first 'rows_to_remove' rows from the beginning\n",
    "non_fraud_to_remove = non_fraud_df.tail(rows_to_remove)\n",
    "\n",
    "# Drop the sampled non-fraud instances from the DataFrame\n",
    "df = df.drop(non_fraud_to_remove.index)\n",
    "\n",
    "# Verify the new balance\n",
    "label_counts = df['isFraud'].value_counts()\n",
    "fraud_ratio = label_counts[1] / len(df)\n",
    "non_fraud_ratio = label_counts[0] / len(df)\n",
    "\n",
    "print(f\"Fraud count: {label_counts[1]}\")\n",
    "print(f\"Non-fraud count: {label_counts[0]}\")\n",
    "print(f\"Fraud ratio: {fraud_ratio:.4f}\")\n",
    "print(f\"Non-fraud ratio: {non_fraud_ratio:.4f}\")\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2a6c004d-9333-4d88-ad92-ae2e55952c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count transactions for each user in nameOrig (senders)\n",
    "orig_counts = df['nameOrig'].value_counts()\n",
    "\n",
    "# Count transactions for each user in nameDest (receivers)\n",
    "dest_counts = df['nameDest'].value_counts()\n",
    "\n",
    "# Combine the counts for both nameOrig and nameDest\n",
    "user_counts = orig_counts.add(dest_counts, fill_value=0)\n",
    "\n",
    "# Filter users with more than one transaction\n",
    "users_with_multiple_transactions = user_counts[user_counts > 1]\n",
    "\n",
    "# Print the users who have more than one transaction\n",
    "if False:\n",
    "    print(users_with_multiple_transactions)\n",
    "    print(\"here\")\n",
    "    print(dest_counts[dest_counts>1])\n",
    "    print(\"here\")\n",
    "    print(orig_counts[orig_counts>1])\n",
    "    print(len(df['nameDest']))\n",
    "    #print(dest_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "19c68098-4397-40d0-b946-7a0230703f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from unique user names to numeric IDs (nodes)\n",
    "user_mapping = {user: idx for idx, user in enumerate(set(df['nameOrig']).union(set(df['nameDest'])))}\n",
    "\n",
    "# Create edges between nameOrig and nameDest\n",
    "src = df['nameOrig'].map(user_mapping).values\n",
    "dst = df['nameDest'].map(user_mapping).values\n",
    "if False:\n",
    "    print(\"test\",len(df.drop_duplicates(subset='nameOrig')))\n",
    "    print(len(set(df['nameDest'])))\n",
    "    print(len(set(df['nameOrig']))+len(set(df['nameDest'])))\n",
    "    print(len(set(df['nameOrig']).union(set(df['nameDest']))))\n",
    "    print(len(set(set(df['nameOrig']).union(set(df['nameDest'])))))\n",
    "    print(len(df['nameOrig']))\n",
    "    idx=0\n",
    "    for item in df['nameDest']:\n",
    "        #print(item)\n",
    "        if 'C985934102' in item:\n",
    "            idx+=1\n",
    "    print(idx)\n",
    "    test=list(df['nameDest'])\n",
    "    print(len((df['nameDest'])))\n",
    "    print('test',len(set(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2bfd81d5-b2e8-4941-bc11-f3bd4257dcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23883 23387  5624 ... 27366  1118  7523]\n"
     ]
    }
   ],
   "source": [
    "print(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5253dc18-6c5e-4523-ab68-d45b6984bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DGL graph from the source and destination nodes\n",
    "g = dgl.graph((src, dst))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8d8d10c-4b83-4564-a4d1-280fae10d4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add transaction amount as edge feature\n",
    "g.edata['amount'] = torch.tensor(df['amount'].values, dtype=torch.float32)\n",
    "\n",
    "# Optional: Add fraud information to edge features\n",
    "g.edata['isFraud'] = torch.tensor(df['isFraud'].values, dtype=torch.float32)\n",
    "\n",
    "# Initialize node features with zeros (this handles all nodes)\n",
    "num_nodes = g.num_nodes()\n",
    "# Group by sender (nameOrig) and calculate the average transaction amount for each user\n",
    "avg_amount_orig = df.groupby('nameOrig')['amount'].mean()\n",
    "\n",
    "# Group by receiver (nameDest) and calculate the average transaction amount for each user\n",
    "avg_amount_dest = df.groupby('nameDest')['amount'].mean()\n",
    "\n",
    "# Now you can use these averages for your nodes\n",
    "avg_amount_orig_dict = avg_amount_orig.to_dict()\n",
    "avg_amount_dest_dict = avg_amount_dest.to_dict()\n",
    "\n",
    "# Initialize node features (average amounts for both orig and dest users)\n",
    "avg_amount_orig_nodes = torch.zeros(num_nodes, dtype=torch.float32)\n",
    "avg_amount_dest_nodes = torch.zeros(num_nodes, dtype=torch.float32)\n",
    "\n",
    "# Assign average amounts to nodes based on user mapping\n",
    "for orig_user, avg_amount in avg_amount_orig_dict.items():\n",
    "    avg_amount_orig_nodes[user_mapping[orig_user]] = avg_amount\n",
    "\n",
    "for dest_user, avg_amount in avg_amount_dest_dict.items():\n",
    "    avg_amount_dest_nodes[user_mapping[dest_user]] = avg_amount\n",
    "\n",
    "# Stack these features and add them to the graph\n",
    "node_features = torch.stack([avg_amount_orig_nodes, avg_amount_dest_nodes], dim=1)\n",
    "\n",
    "g.ndata['features'] = node_features\n",
    "\n",
    "node_labels = torch.zeros(num_nodes, dtype=torch.float32)\n",
    "\n",
    "# Map 'isFraud' values to corresponding nodes based on user mapping\n",
    "for user, fraud in df[['nameOrig', 'isFraud']].values:\n",
    "    node_labels[user_mapping[user]] = fraud\n",
    "\n",
    "# Map 'isFraud' to destination nodes (nameDest)\n",
    "for dest_user, fraud in df[['nameDest', 'isFraud']].values:\n",
    "    node_labels[user_mapping[dest_user]] = fraud\n",
    "    \n",
    "node_features = torch.stack([avg_amount_orig_nodes, avg_amount_dest_nodes], dim=1)\n",
    "\n",
    "g.ndata['features'] = node_features\n",
    "\n",
    "# Store the fraud labels in g.ndata['isFraud']\n",
    "g.ndata['isFraud'] = node_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8642eee4-682c-4615-af77-3422f2e46e47",
   "metadata": {},
   "source": [
    "71742 43429"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0e37e5f8-5d2f-492e-8fcc-db40ce4f3e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DGLGraph.num_edges of Graph(num_nodes=31959, num_edges=17745,\n",
       "      ndata_schemes={'features': Scheme(shape=(2,), dtype=torch.float32), 'isFraud': Scheme(shape=(), dtype=torch.float32)}\n",
       "      edata_schemes={'amount': Scheme(shape=(), dtype=torch.float32), 'isFraud': Scheme(shape=(), dtype=torch.float32)})>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edata['isFraud'].shape\n",
    "#node_features.shape\n",
    "g.num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "788366e2-8e69-40f7-82d7-5bb92f9a1ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print graph information\n",
    "#print(g)\n",
    "\n",
    "# Visualize the graph using NetworkX (convert DGL graph to NetworkX for visualization)\n",
    "#nx_graph = g.to_networkx()\n",
    "\n",
    "# Optional: Visualize using a layout for better readability\n",
    "#pos = nx.spring_layout(nx_graph)  # Use a layout for better visualization\n",
    "#plt.figure(figsize=(12, 12))\n",
    "#nx.draw(nx_graph, pos, node_size=50, node_color='skyblue', font_size=10, with_labels=True)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe561538-118f-4c17-b6cc-54460d44f063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge Features (Transaction Amounts):\n",
      "tensor([9.8396e+03, 1.8643e+03, 1.8100e+02,  ..., 6.3114e+06, 8.5000e+05,\n",
      "        8.5000e+05])\n"
     ]
    }
   ],
   "source": [
    "# Assuming that you have edge features like transaction amounts or fraud status\n",
    "edge_features = g.edata.get('amount', None)  # Assuming 'amount' is an edge feature\n",
    "if edge_features is not None:\n",
    "    print(\"Edge Features (Transaction Amounts):\")\n",
    "    print(edge_features)\n",
    "else:\n",
    "    print(\"No edge features found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ecd2e705-81a6-4e96-a46a-7e8af83ea77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 80% of nodes for training\n",
    "num_train_nodes = int(0.8 * num_nodes)\n",
    "train_indices = torch.randperm(num_nodes)[:num_train_nodes]  \n",
    "test_indices = torch.tensor([i for i in range(num_nodes) if i not in train_indices])\n",
    "\n",
    "# Create train/test masks\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "train_mask[train_indices] = True\n",
    "test_mask[test_indices] = True\n",
    "\n",
    "# Assign to graph\n",
    "g.ndata['train_mask'] = train_mask\n",
    "g.ndata['test_mask'] = test_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5b521fd7-bdfd-47eb-a894-4f4175fd2ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GraphSAGE model for fraud detection\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_feats, out_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.layer1 = dgl.nn.SAGEConv(in_feats, hidden_feats, 'mean')\n",
    "        self.layer2 = dgl.nn.SAGEConv(hidden_feats, out_feats, 'mean')\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        #self.fc = nn.Linear(out_feats * 2, 1)  # * Concatenate source and destination node embeddings *\n",
    "        self.fc = nn.Linear(out_feats, 1)  # Output a single value per node (fraud score)\n",
    "        \n",
    "    def forward(self, g, features):\n",
    "        # Apply first GraphSAGE layer and ReLU\n",
    "        x = self.layer1(g, features)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Apply second GraphSAGE layer to get node embeddings\n",
    "        x = self.layer2(g, x)\n",
    "        \n",
    "        # Output a prediction for each node\n",
    "        logits = self.fc(x).squeeze()  # Output a single value per node\n",
    "        return logits\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "caf5f966-4635-469e-a2d6-2bf70d46c371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud count: 8213\n",
      "Non-fraud count: 9532\n",
      "Fraud ratio: 0.4628\n",
      "Non-fraud ratio: 0.5372\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each label in the 'isFraud' column\n",
    "label_counts = df['isFraud'].value_counts()\n",
    "\n",
    "# Calculate the proportion of each class\n",
    "fraud_ratio = label_counts[1] / len(df)  # Assuming '1' represents fraud\n",
    "non_fraud_ratio = label_counts[0] / len(df)  # Assuming '0' represents non-fraud\n",
    "\n",
    "# Print the results\n",
    "print(f\"Fraud count: {label_counts[1]}\")\n",
    "print(f\"Non-fraud count: {label_counts[0]}\")\n",
    "print(f\"Fraud ratio: {fraud_ratio:.4f}\")\n",
    "print(f\"Non-fraud ratio: {non_fraud_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9f542233-e155-4918-8816-b1e3e427d999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/500, Loss: 205846.90625\n",
      "Epoch 4/500, Loss: 78685.96875\n",
      "Epoch 6/500, Loss: 31865.6875\n",
      "Epoch 8/500, Loss: 24021.21484375\n",
      "Epoch 10/500, Loss: 25621.240234375\n",
      "Epoch 12/500, Loss: 28713.033203125\n",
      "Epoch 14/500, Loss: 31108.080078125\n",
      "Epoch 16/500, Loss: 33092.46484375\n",
      "Epoch 18/500, Loss: 33154.8203125\n",
      "Epoch 20/500, Loss: 33238.66015625\n",
      "Epoch 22/500, Loss: 32864.29296875\n",
      "Epoch 24/500, Loss: 32042.888671875\n",
      "Epoch 26/500, Loss: 30097.861328125\n",
      "Epoch 28/500, Loss: 29340.25390625\n",
      "Epoch 30/500, Loss: 27079.31640625\n",
      "Epoch 32/500, Loss: 25707.421875\n",
      "Epoch 34/500, Loss: 23547.185546875\n",
      "Epoch 36/500, Loss: 22040.484375\n",
      "Epoch 38/500, Loss: 21229.841796875\n",
      "Epoch 40/500, Loss: 19104.486328125\n",
      "Epoch 42/500, Loss: 17995.50390625\n",
      "Epoch 44/500, Loss: 16580.5078125\n",
      "Epoch 46/500, Loss: 15220.8046875\n",
      "Epoch 48/500, Loss: 14936.611328125\n",
      "Epoch 50/500, Loss: 13884.0771484375\n",
      "Epoch 52/500, Loss: 13946.3046875\n",
      "Epoch 54/500, Loss: 13499.8935546875\n",
      "Epoch 56/500, Loss: 13130.6484375\n",
      "Epoch 58/500, Loss: 12817.8681640625\n",
      "Epoch 60/500, Loss: 11633.576171875\n",
      "Epoch 62/500, Loss: 11651.9833984375\n",
      "Epoch 64/500, Loss: 11866.267578125\n",
      "Epoch 66/500, Loss: 10818.1201171875\n",
      "Epoch 68/500, Loss: 10120.4228515625\n",
      "Epoch 70/500, Loss: 10028.5283203125\n",
      "Epoch 72/500, Loss: 9462.6376953125\n",
      "Epoch 74/500, Loss: 8896.4462890625\n",
      "Epoch 76/500, Loss: 8626.0390625\n",
      "Epoch 78/500, Loss: 8601.5751953125\n",
      "Epoch 80/500, Loss: 8541.826171875\n",
      "Epoch 82/500, Loss: 8171.89697265625\n",
      "Epoch 84/500, Loss: 7760.66455078125\n",
      "Epoch 86/500, Loss: 7387.9541015625\n",
      "Epoch 88/500, Loss: 7357.47119140625\n",
      "Epoch 90/500, Loss: 6901.1611328125\n",
      "Epoch 92/500, Loss: 6686.83349609375\n",
      "Epoch 94/500, Loss: 6327.92333984375\n",
      "Epoch 96/500, Loss: 6110.2841796875\n",
      "Epoch 98/500, Loss: 5832.8427734375\n",
      "Epoch 100/500, Loss: 5678.2109375\n",
      "Epoch 102/500, Loss: 5580.7275390625\n",
      "Epoch 104/500, Loss: 5348.71044921875\n",
      "Epoch 106/500, Loss: 5068.47607421875\n",
      "Epoch 108/500, Loss: 5076.3984375\n",
      "Epoch 110/500, Loss: 4740.53076171875\n",
      "Epoch 112/500, Loss: 4495.2119140625\n",
      "Epoch 114/500, Loss: 4498.7314453125\n",
      "Epoch 116/500, Loss: 4409.00048828125\n",
      "Epoch 118/500, Loss: 4127.73193359375\n",
      "Epoch 120/500, Loss: 4043.066650390625\n",
      "Epoch 122/500, Loss: 3912.848388671875\n",
      "Epoch 124/500, Loss: 3706.519775390625\n",
      "Epoch 126/500, Loss: 3592.640625\n",
      "Epoch 128/500, Loss: 3620.57080078125\n",
      "Epoch 130/500, Loss: 3390.322509765625\n",
      "Epoch 132/500, Loss: 3219.851806640625\n",
      "Epoch 134/500, Loss: 3154.704345703125\n",
      "Epoch 136/500, Loss: 3191.087646484375\n",
      "Epoch 138/500, Loss: 3047.284912109375\n",
      "Epoch 140/500, Loss: 3014.98046875\n",
      "Epoch 142/500, Loss: 2799.68359375\n",
      "Epoch 144/500, Loss: 2649.105224609375\n",
      "Epoch 146/500, Loss: 2574.615966796875\n",
      "Epoch 148/500, Loss: 2383.04345703125\n",
      "Epoch 150/500, Loss: 2539.9462890625\n",
      "Epoch 152/500, Loss: 2339.07275390625\n",
      "Epoch 154/500, Loss: 2274.848876953125\n",
      "Epoch 156/500, Loss: 2235.97265625\n",
      "Epoch 158/500, Loss: 2074.773681640625\n",
      "Epoch 160/500, Loss: 1982.5352783203125\n",
      "Epoch 162/500, Loss: 1924.4127197265625\n",
      "Epoch 164/500, Loss: 1876.768798828125\n",
      "Epoch 166/500, Loss: 1850.2047119140625\n",
      "Epoch 168/500, Loss: 1793.9608154296875\n",
      "Epoch 170/500, Loss: 1698.7366943359375\n",
      "Epoch 172/500, Loss: 1715.601806640625\n",
      "Epoch 174/500, Loss: 1549.7744140625\n",
      "Epoch 176/500, Loss: 1579.691650390625\n",
      "Epoch 178/500, Loss: 1500.314208984375\n",
      "Epoch 180/500, Loss: 1450.0340576171875\n",
      "Epoch 182/500, Loss: 1469.787353515625\n",
      "Epoch 184/500, Loss: 1441.6575927734375\n",
      "Epoch 186/500, Loss: 1402.3070068359375\n",
      "Epoch 188/500, Loss: 1295.1910400390625\n",
      "Epoch 190/500, Loss: 1270.32470703125\n",
      "Epoch 192/500, Loss: 1197.3504638671875\n",
      "Epoch 194/500, Loss: 1206.5228271484375\n",
      "Epoch 196/500, Loss: 1147.9083251953125\n",
      "Epoch 198/500, Loss: 1054.95703125\n",
      "Epoch 200/500, Loss: 1105.70458984375\n",
      "Epoch 202/500, Loss: 1026.2901611328125\n",
      "Epoch 204/500, Loss: 1033.7034912109375\n",
      "Epoch 206/500, Loss: 978.7169189453125\n",
      "Epoch 208/500, Loss: 1033.813232421875\n",
      "Epoch 210/500, Loss: 977.3136596679688\n",
      "Epoch 212/500, Loss: 902.8988647460938\n",
      "Epoch 214/500, Loss: 879.63916015625\n",
      "Epoch 216/500, Loss: 850.0902709960938\n",
      "Epoch 218/500, Loss: 860.7496337890625\n",
      "Epoch 220/500, Loss: 786.43359375\n",
      "Epoch 222/500, Loss: 787.5560913085938\n",
      "Epoch 224/500, Loss: 774.7293701171875\n",
      "Epoch 226/500, Loss: 762.8921508789062\n",
      "Epoch 228/500, Loss: 704.3505859375\n",
      "Epoch 230/500, Loss: 730.5677490234375\n",
      "Epoch 232/500, Loss: 683.0411987304688\n",
      "Epoch 234/500, Loss: 663.4239501953125\n",
      "Epoch 236/500, Loss: 701.8021850585938\n",
      "Epoch 238/500, Loss: 628.6901245117188\n",
      "Epoch 240/500, Loss: 598.8396606445312\n",
      "Epoch 242/500, Loss: 578.8836669921875\n",
      "Epoch 244/500, Loss: 606.5358276367188\n",
      "Epoch 246/500, Loss: 543.979736328125\n",
      "Epoch 248/500, Loss: 579.3760986328125\n",
      "Epoch 250/500, Loss: 530.3267211914062\n",
      "Epoch 252/500, Loss: 574.0948486328125\n",
      "Epoch 254/500, Loss: 549.3768310546875\n",
      "Epoch 256/500, Loss: 553.9793701171875\n",
      "Epoch 258/500, Loss: 516.5818481445312\n",
      "Epoch 260/500, Loss: 458.49981689453125\n",
      "Epoch 262/500, Loss: 507.1155700683594\n",
      "Epoch 264/500, Loss: 471.60760498046875\n",
      "Epoch 266/500, Loss: 472.5639343261719\n",
      "Epoch 268/500, Loss: 434.63433837890625\n",
      "Epoch 270/500, Loss: 434.6124267578125\n",
      "Epoch 272/500, Loss: 427.5004577636719\n",
      "Epoch 274/500, Loss: 415.4986572265625\n",
      "Epoch 276/500, Loss: 395.662841796875\n",
      "Epoch 278/500, Loss: 420.7435302734375\n",
      "Epoch 280/500, Loss: 384.54150390625\n",
      "Epoch 282/500, Loss: 390.33355712890625\n",
      "Epoch 284/500, Loss: 404.7119445800781\n",
      "Epoch 286/500, Loss: 382.9916687011719\n",
      "Epoch 288/500, Loss: 336.4590759277344\n",
      "Epoch 290/500, Loss: 362.0765686035156\n",
      "Epoch 292/500, Loss: 353.3456115722656\n",
      "Epoch 294/500, Loss: 349.211669921875\n",
      "Epoch 296/500, Loss: 321.4170227050781\n",
      "Epoch 298/500, Loss: 330.23797607421875\n",
      "Epoch 300/500, Loss: 322.4034729003906\n",
      "Epoch 302/500, Loss: 320.3970031738281\n",
      "Epoch 304/500, Loss: 299.0335388183594\n",
      "Epoch 306/500, Loss: 331.23388671875\n",
      "Epoch 308/500, Loss: 305.2032775878906\n",
      "Epoch 310/500, Loss: 312.08892822265625\n",
      "Epoch 312/500, Loss: 297.533447265625\n",
      "Epoch 314/500, Loss: 284.706298828125\n",
      "Epoch 316/500, Loss: 264.6781005859375\n",
      "Epoch 318/500, Loss: 309.69281005859375\n",
      "Epoch 320/500, Loss: 281.3727722167969\n",
      "Epoch 322/500, Loss: 272.9715576171875\n",
      "Epoch 324/500, Loss: 280.3169250488281\n",
      "Epoch 326/500, Loss: 269.4159240722656\n",
      "Epoch 328/500, Loss: 272.2200622558594\n",
      "Epoch 330/500, Loss: 260.28057861328125\n",
      "Epoch 332/500, Loss: 246.46568298339844\n",
      "Epoch 334/500, Loss: 249.08816528320312\n",
      "Epoch 336/500, Loss: 242.890869140625\n",
      "Epoch 338/500, Loss: 237.93006896972656\n",
      "Epoch 340/500, Loss: 224.55455017089844\n",
      "Epoch 342/500, Loss: 222.96690368652344\n",
      "Epoch 344/500, Loss: 248.45217895507812\n",
      "Epoch 346/500, Loss: 234.484375\n",
      "Epoch 348/500, Loss: 225.9840087890625\n",
      "Epoch 350/500, Loss: 231.47055053710938\n",
      "Epoch 352/500, Loss: 212.99520874023438\n",
      "Epoch 354/500, Loss: 209.76919555664062\n",
      "Epoch 356/500, Loss: 192.67477416992188\n",
      "Epoch 358/500, Loss: 214.385986328125\n",
      "Epoch 360/500, Loss: 212.5927734375\n",
      "Epoch 362/500, Loss: 208.7584991455078\n",
      "Epoch 364/500, Loss: 216.69784545898438\n",
      "Epoch 366/500, Loss: 211.1826629638672\n",
      "Epoch 368/500, Loss: 217.15573120117188\n",
      "Epoch 370/500, Loss: 220.55018615722656\n",
      "Epoch 372/500, Loss: 216.7362060546875\n",
      "Epoch 374/500, Loss: 202.00633239746094\n",
      "Epoch 376/500, Loss: 176.24876403808594\n",
      "Epoch 378/500, Loss: 191.792236328125\n",
      "Epoch 380/500, Loss: 180.0911865234375\n",
      "Epoch 382/500, Loss: 175.99542236328125\n",
      "Epoch 384/500, Loss: 187.77059936523438\n",
      "Epoch 386/500, Loss: 190.93524169921875\n",
      "Epoch 388/500, Loss: 180.9483642578125\n",
      "Epoch 390/500, Loss: 167.00006103515625\n",
      "Epoch 392/500, Loss: 168.76341247558594\n",
      "Epoch 394/500, Loss: 163.1814422607422\n",
      "Epoch 396/500, Loss: 158.9009246826172\n",
      "Epoch 398/500, Loss: 159.05250549316406\n",
      "Epoch 400/500, Loss: 154.06332397460938\n",
      "Epoch 402/500, Loss: 150.02459716796875\n",
      "Epoch 404/500, Loss: 151.83642578125\n",
      "Epoch 406/500, Loss: 147.28822326660156\n",
      "Epoch 408/500, Loss: 131.32591247558594\n",
      "Epoch 410/500, Loss: 137.88465881347656\n",
      "Epoch 412/500, Loss: 140.07754516601562\n",
      "Epoch 414/500, Loss: 138.65391540527344\n",
      "Epoch 416/500, Loss: 135.4324493408203\n",
      "Epoch 418/500, Loss: 136.34445190429688\n",
      "Epoch 420/500, Loss: 131.127197265625\n",
      "Epoch 422/500, Loss: 128.09014892578125\n",
      "Epoch 424/500, Loss: 123.1385269165039\n",
      "Epoch 426/500, Loss: 130.0647735595703\n",
      "Epoch 428/500, Loss: 124.34363555908203\n",
      "Epoch 430/500, Loss: 123.60181427001953\n",
      "Epoch 432/500, Loss: 115.8048095703125\n",
      "Epoch 434/500, Loss: 121.10318756103516\n",
      "Epoch 436/500, Loss: 120.43746948242188\n",
      "Epoch 438/500, Loss: 108.48297882080078\n",
      "Epoch 440/500, Loss: 112.59369659423828\n",
      "Epoch 442/500, Loss: 109.08799743652344\n",
      "Epoch 444/500, Loss: 110.79422760009766\n",
      "Epoch 446/500, Loss: 108.765380859375\n",
      "Epoch 448/500, Loss: 119.84556579589844\n",
      "Epoch 450/500, Loss: 129.35202026367188\n",
      "Epoch 452/500, Loss: 121.82872772216797\n",
      "Epoch 454/500, Loss: 115.98528289794922\n",
      "Epoch 456/500, Loss: 108.1395263671875\n",
      "Epoch 458/500, Loss: 112.59817504882812\n",
      "Epoch 460/500, Loss: 100.8150863647461\n",
      "Epoch 462/500, Loss: 94.52108001708984\n",
      "Epoch 464/500, Loss: 104.65007781982422\n",
      "Epoch 466/500, Loss: 98.11578369140625\n",
      "Epoch 468/500, Loss: 87.80535125732422\n",
      "Epoch 470/500, Loss: 84.6341552734375\n",
      "Epoch 472/500, Loss: 84.97056579589844\n",
      "Epoch 474/500, Loss: 95.72183227539062\n",
      "Epoch 476/500, Loss: 89.20862579345703\n",
      "Epoch 478/500, Loss: 89.68855285644531\n",
      "Epoch 480/500, Loss: 90.53763580322266\n",
      "Epoch 482/500, Loss: 82.05020141601562\n",
      "Epoch 484/500, Loss: 82.71150207519531\n",
      "Epoch 486/500, Loss: 76.6791000366211\n",
      "Epoch 488/500, Loss: 76.97584533691406\n",
      "Epoch 490/500, Loss: 74.1747055053711\n",
      "Epoch 492/500, Loss: 79.29505157470703\n",
      "Epoch 494/500, Loss: 78.9964828491211\n",
      "Epoch 496/500, Loss: 82.57935333251953\n",
      "Epoch 498/500, Loss: 83.32758331298828\n",
      "Epoch 500/500, Loss: 79.7648696899414\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "in_feats = 2  # balanceOrig and balanceDest features\n",
    "hidden_feats = 64\n",
    "out_feats = 1  # Fraud (binary classification)\n",
    "\n",
    "#pos_weight = torch.tensor([non_fraud_ratio/fraud_ratio],dtype=torch.float)\n",
    "pos_weight = torch.tensor([1.0],dtype=torch.float)\n",
    "\n",
    "\n",
    "model = GraphSAGE(in_feats, hidden_feats, out_feats)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "epochs = 500\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    # Forward pass\n",
    "    logits = model(g, g.ndata['features'])\n",
    "    #print(logits.shape)\n",
    "\n",
    "    # Get target labels for the fraud detection task\n",
    "    labels = g.ndata['isFraud']\n",
    "    # Compute loss (use train_mask to filter out test edges)\n",
    "    #print(\"labels\",labels[train_mask].view(-1,1).shape)\n",
    "    #print(\"logits\", logits[train_mask].view(-1,1).shape)\n",
    "    loss = loss_fn(logits[train_mask].view(-1,1), labels[train_mask].view(-1,1))\n",
    "    \n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss every few epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c15695-ca6e-49ef-81e7-b66b7618a1d7",
   "metadata": {},
   "source": [
    "Epoch 2/20, Loss: 50026236.0\n",
    "Epoch 4/20, Loss: 21910472.0\n",
    "Epoch 6/20, Loss: 12671362.0\n",
    "Epoch 8/20, Loss: 12492275.0\n",
    "Epoch 10/20, Loss: 13373789.0\n",
    "Epoch 12/20, Loss: 14267830.0\n",
    "Epoch 14/20, Loss: 14137046.0\n",
    "Epoch 16/20, Loss: 12949893.0\n",
    "Epoch 18/20, Loss: 11810090.0\n",
    "Epoch 20/20, Loss: 10091464.0\n",
    "0.1\n",
    "Accuracy: 0.7332\n",
    "Recall: 0.0086\n",
    "F1 Score: 0.0073\n",
    "0.01\n",
    "Accuracy: 0.7535\n",
    "Recall: 0.0039\n",
    "F1 Score: 0.0036\n",
    "0.2\n",
    "Accuracy: 0.7378\n",
    "Recall: 0.0102\n",
    "F1 Score: 0.0087\n",
    "0.4\n",
    "Accuracy: 0.7405\n",
    "Recall: 0.0079\n",
    "F1 Score: 0.0068"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3d073edc-243e-4b6e-9d3e-9ac7d47ce144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['features', 'isFraud', 'train_mask', 'test_mask'])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.ndata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "45d2bbf5-bda6-484a-9a51-8faaab1820ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.1272e+03, 0.0000e+00],\n",
      "        [0.0000e+00, 5.1361e+05],\n",
      "        [0.0000e+00, 1.3751e+05],\n",
      "        ...,\n",
      "        [2.4206e+03, 0.0000e+00],\n",
      "        [3.5231e+06, 0.0000e+00],\n",
      "        [5.3386e+06, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "print(g.ndata['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "23e85df0-9f6b-456d-82b1-b8e41577a6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6189\n",
      "Recall: 0.6081\n",
      "Precision:0.6370\n",
      "F1 Score: 0.6222\n",
      "Sample transaction mappings with user names:\n",
      "{'orig_user': 'C1254777952', 'predicted_label': 1, 'true_label': 1, 'avg_amount_orig': 0.0, 'avg_amount_dest': 137508.015625}\n",
      "{'orig_user': 'C1595140561', 'predicted_label': 1, 'true_label': 1, 'avg_amount_orig': 0.0, 'avg_amount_dest': 57543.33984375}\n",
      "{'orig_user': 'C699574604', 'predicted_label': 0, 'true_label': 0, 'avg_amount_orig': 6234.93994140625, 'avg_amount_dest': 0.0}\n",
      "{'orig_user': 'M590399893', 'predicted_label': 1, 'true_label': 0, 'avg_amount_orig': 0.0, 'avg_amount_dest': 8869.7802734375}\n",
      "{'orig_user': 'C422243042', 'predicted_label': 0, 'true_label': 0, 'avg_amount_orig': 9738.48046875, 'avg_amount_dest': 0.0}\n",
      "{'orig_user': 'M414634945', 'predicted_label': 1, 'true_label': 0, 'avg_amount_orig': 0.0, 'avg_amount_dest': 760.739990234375}\n",
      "{'orig_user': 'C1242414689', 'predicted_label': 1, 'true_label': 1, 'avg_amount_orig': 0.0, 'avg_amount_dest': 151105.96875}\n",
      "{'orig_user': 'C745835029', 'predicted_label': 0, 'true_label': 0, 'avg_amount_orig': 58930.328125, 'avg_amount_dest': 0.0}\n",
      "{'orig_user': 'C674306325', 'predicted_label': 1, 'true_label': 1, 'avg_amount_orig': 0.0, 'avg_amount_dest': 722832.9375}\n",
      "{'orig_user': 'C1357770570', 'predicted_label': 0, 'true_label': 1, 'avg_amount_orig': 669627.4375, 'avg_amount_dest': 0.0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(g, g.ndata['features'])\n",
    "\n",
    "    # Convert logits to probabilities\n",
    "    predictions = torch.sigmoid(logits).squeeze()\n",
    "    \n",
    "    # Apply threshold of to classify fraud\n",
    "    predicted_labels = (predictions > 0.5).float()\n",
    "    predicted_labels = predicted_labels[test_mask]  # Apply test_mask here\n",
    "    # Get actual labels\n",
    "    #true_labels = g.edata['isFraud']\n",
    "    true_labels = g.ndata['isFraud'][test_mask]  # Apply test_mask here\n",
    "    #amounts=g.ndata['amount'][test_mask]\n",
    "    # Store results in a list of dictionaries\n",
    "    # Convert node indices back to user names\n",
    "    reverse_user_mapping = {v: k for k, v in user_mapping.items()}  # Reverse mapping\n",
    "    \n",
    "    # Retrieve node indices from test_mask\n",
    "    test_node_indices = test_mask.nonzero().squeeze().tolist()\n",
    "\n",
    "    node_features_test = g.ndata['features'][test_mask]  # Shape: (num_test_nodes, 2)\n",
    "    \n",
    "    avg_amount_orig_test = node_features_test[:, 0].tolist()\n",
    "    avg_amount_dest_test = node_features_test[:, 1].tolist()\n",
    "    \n",
    "    # Map predictions back to transactions with their original balances\n",
    "    mapped_results = [\n",
    "        {\n",
    "            \"orig_user\": reverse_user_mapping[node],\n",
    "            \"predicted_label\": int(pred),\n",
    "            \"true_label\": int(true_lab),\n",
    "            \"avg_amount_orig\": avg_amount_orig,\n",
    "            \"avg_amount_dest\": avg_amount_dest\n",
    "        }\n",
    "        for node, pred, true_lab, avg_amount_orig, avg_amount_dest in zip(\n",
    "            test_node_indices, predicted_labels.tolist(), true_labels.tolist(), avg_amount_orig_test, avg_amount_dest_test\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Compute accuracy manually\n",
    "    correct = (predicted_labels == true_labels).sum().item()\n",
    "    total = true_labels.size(0)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    # Print evaluation results\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    # Calculate F1-Score\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Precision:{precision:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "# Print some mapped results\n",
    "print(\"Sample transaction mappings with user names:\")\n",
    "for res in mapped_results[:10]:\n",
    "    print(res)\n",
    "    #if res['balance_orig']>0 and res['balance_dest']>0:\n",
    "    #    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1c244cd-c6db-48cc-b2b6-56fd33b2d3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[      0.0000,  137508.0156],\n",
      "        [      0.0000,    9458.1602],\n",
      "        [  43935.0586,       0.0000],\n",
      "        ...,\n",
      "        [1375603.2500,       0.0000],\n",
      "        [3523089.5000,       0.0000],\n",
      "        [5338583.5000,       0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "207ba890-7fc4-4444-a169-f08dfebd5356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16301)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(labels==1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
