{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2fda4b0-72ce-4e28-9c2a-b9d9248a6615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a sample Python script.\n",
    "import pandas as pd\n",
    "import torch\n",
    "device = torch.device('cpu')\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import dgl.function as fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f18b6091-298f-4e96-933a-64499e87ed3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../data/PaySim_kaggle.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497df701-9ae7-49b5-8e86-daa20fb723d4",
   "metadata": {},
   "source": [
    "Adjust data proportions as the fraud data is heavily biased having less fraudulant cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e65c8bcb-5856-4d91-9eb1-8a090c0b2556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud count: 8213\n",
      "Non-fraud count: 63545\n",
      "Fraud ratio: 0.1145\n",
      "Non-fraud ratio: 0.8855\n",
      "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
      "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
      "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
      "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
      "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
      "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
      "\n",
      "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
      "0  M1979787155             0.0             0.0        0               0  \n",
      "1  M2044282225             0.0             0.0        0               0  \n",
      "2   C553264065             0.0             0.0        1               0  \n",
      "3    C38997010         21182.0             0.0        1               0  \n",
      "4  M1230701703             0.0             0.0        0               0  \n"
     ]
    }
   ],
   "source": [
    "# Set the proportion of non-fraud to remove (e.g., 50% of non-fraud instances)\n",
    "remove_fraction = 0.9985\n",
    "\n",
    "# Separate the fraud and non-fraud instances\n",
    "fraud_df = df[df['isFraud'] == 1]\n",
    "non_fraud_df = df[df['isFraud'] == 0]\n",
    "\n",
    "# Randomly sample and remove 'remove_fraction' proportion of non-fraud instances\n",
    "# Calculate the number of rows to remove based on the fraction\n",
    "rows_to_remove = int(len(non_fraud_df) * remove_fraction)\n",
    "\n",
    "# Select the first 'rows_to_remove' rows from the beginning\n",
    "non_fraud_to_remove = non_fraud_df.tail(rows_to_remove)\n",
    "\n",
    "# Drop the sampled non-fraud instances from the DataFrame\n",
    "df = df.drop(non_fraud_to_remove.index)\n",
    "\n",
    "# Verify the new balance\n",
    "label_counts = df['isFraud'].value_counts()\n",
    "fraud_ratio = label_counts[1] / len(df)\n",
    "non_fraud_ratio = label_counts[0] / len(df)\n",
    "\n",
    "print(f\"Fraud count: {label_counts[1]}\")\n",
    "print(f\"Non-fraud count: {label_counts[0]}\")\n",
    "print(f\"Fraud ratio: {fraud_ratio:.4f}\")\n",
    "print(f\"Non-fraud ratio: {non_fraud_ratio:.4f}\")\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a6c004d-9333-4d88-ad92-ae2e55952c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count transactions for each user in nameOrig (senders)\n",
    "orig_counts = df['nameOrig'].value_counts()\n",
    "\n",
    "# Count transactions for each user in nameDest (receivers)\n",
    "dest_counts = df['nameDest'].value_counts()\n",
    "\n",
    "# Combine the counts for both nameOrig and nameDest\n",
    "user_counts = orig_counts.add(dest_counts, fill_value=0)\n",
    "\n",
    "# Filter users with more than one transaction\n",
    "users_with_multiple_transactions = user_counts[user_counts > 1]\n",
    "\n",
    "# Print the users who have more than one transaction\n",
    "if False:\n",
    "    print(users_with_multiple_transactions)\n",
    "    print(\"here\")\n",
    "    print(dest_counts[dest_counts>1])\n",
    "    print(\"here\")\n",
    "    print(orig_counts[orig_counts>1])\n",
    "    print(len(df['nameDest']))\n",
    "    #print(dest_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19c68098-4397-40d0-b946-7a0230703f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from unique user names to numeric IDs (nodes)\n",
    "user_mapping = {user: idx for idx, user in enumerate(set(df['nameOrig']).union(set(df['nameDest'])))}\n",
    "\n",
    "# Create edges between nameOrig and nameDest\n",
    "src = df['nameOrig'].map(user_mapping).values\n",
    "dst = df['nameDest'].map(user_mapping).values\n",
    "if False:\n",
    "    print(\"test\",len(df.drop_duplicates(subset='nameOrig')))\n",
    "    print(len(set(df['nameDest'])))\n",
    "    print(len(set(df['nameOrig']))+len(set(df['nameDest'])))\n",
    "    print(len(set(df['nameOrig']).union(set(df['nameDest']))))\n",
    "    print(len(set(set(df['nameOrig']).union(set(df['nameDest'])))))\n",
    "    print(len(df['nameOrig']))\n",
    "    idx=0\n",
    "    for item in df['nameDest']:\n",
    "        #print(item)\n",
    "        if 'C985934102' in item:\n",
    "            idx+=1\n",
    "    print(idx)\n",
    "    test=list(df['nameDest'])\n",
    "    print(len((df['nameDest'])))\n",
    "    print('test',len(set(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bfd81d5-b2e8-4941-bc11-f3bd4257dcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21532 21097 34075 ... 82559 29940 35776]\n"
     ]
    }
   ],
   "source": [
    "print(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5253dc18-6c5e-4523-ab68-d45b6984bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DGL graph from the source and destination nodes\n",
    "g = dgl.graph((src, dst))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8d8d10c-4b83-4564-a4d1-280fae10d4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add transaction amount as edge feature\n",
    "g.edata['amount'] = torch.tensor(df['amount'].values, dtype=torch.float32)\n",
    "\n",
    "# Optional: Add fraud information to edge features\n",
    "g.edata['isFraud'] = torch.tensor(df['isFraud'].values, dtype=torch.float32)\n",
    "\n",
    "# Initialize node features with zeros (this handles all nodes)\n",
    "num_nodes = g.num_nodes()\n",
    "# Group by sender (nameOrig) and calculate the average transaction amount for each user\n",
    "avg_amount_orig = df.groupby('nameOrig')['amount'].mean()\n",
    "\n",
    "# Group by receiver (nameDest) and calculate the average transaction amount for each user\n",
    "avg_amount_dest = df.groupby('nameDest')['amount'].mean()\n",
    "\n",
    "# Now you can use these averages for your nodes\n",
    "avg_amount_orig_dict = avg_amount_orig.to_dict()\n",
    "avg_amount_dest_dict = avg_amount_dest.to_dict()\n",
    "\n",
    "# Initialize node features (average amounts for both orig and dest users)\n",
    "avg_amount_orig_nodes = torch.zeros(num_nodes, dtype=torch.float32)\n",
    "avg_amount_dest_nodes = torch.zeros(num_nodes, dtype=torch.float32)\n",
    "\n",
    "# Assign average amounts to nodes based on user mapping\n",
    "for orig_user, avg_amount in avg_amount_orig_dict.items():\n",
    "    avg_amount_orig_nodes[user_mapping[orig_user]] = avg_amount\n",
    "\n",
    "for dest_user, avg_amount in avg_amount_dest_dict.items():\n",
    "    avg_amount_dest_nodes[user_mapping[dest_user]] = avg_amount\n",
    "\n",
    "# Stack these features and add them to the graph\n",
    "node_features = torch.stack([avg_amount_orig_nodes, avg_amount_dest_nodes], dim=1)\n",
    "\n",
    "g.ndata['features'] = node_features\n",
    "\n",
    "node_labels = torch.zeros(num_nodes, dtype=torch.float32)\n",
    "\n",
    "# Map 'isFraud' values to corresponding nodes based on user mapping\n",
    "for user, fraud in df[['nameOrig', 'isFraud']].values:\n",
    "    node_labels[user_mapping[user]] = fraud\n",
    "\n",
    "# Map 'isFraud' to destination nodes (nameDest)\n",
    "for dest_user, fraud in df[['nameDest', 'isFraud']].values:\n",
    "    node_labels[user_mapping[dest_user]] = fraud\n",
    "    \n",
    "node_features = torch.stack([avg_amount_orig_nodes, avg_amount_dest_nodes], dim=1)\n",
    "\n",
    "g.ndata['features'] = node_features\n",
    "\n",
    "# Store the fraud labels in g.ndata['isFraud']\n",
    "g.ndata['isFraud'] = node_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8642eee4-682c-4615-af77-3422f2e46e47",
   "metadata": {},
   "source": [
    "71742 43429"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e37e5f8-5d2f-492e-8fcc-db40ce4f3e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DGLGraph.num_edges of Graph(num_nodes=115202, num_edges=71758,\n",
       "      ndata_schemes={'features': Scheme(shape=(2,), dtype=torch.float32), 'isFraud': Scheme(shape=(), dtype=torch.float32)}\n",
       "      edata_schemes={'amount': Scheme(shape=(), dtype=torch.float32), 'isFraud': Scheme(shape=(), dtype=torch.float32)})>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edata['isFraud'].shape\n",
    "#node_features.shape\n",
    "g.num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "788366e2-8e69-40f7-82d7-5bb92f9a1ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print graph information\n",
    "#print(g)\n",
    "\n",
    "# Visualize the graph using NetworkX (convert DGL graph to NetworkX for visualization)\n",
    "#nx_graph = g.to_networkx()\n",
    "\n",
    "# Optional: Visualize using a layout for better readability\n",
    "#pos = nx.spring_layout(nx_graph)  # Use a layout for better visualization\n",
    "#plt.figure(figsize=(12, 12))\n",
    "#nx.draw(nx_graph, pos, node_size=50, node_color='skyblue', font_size=10, with_labels=True)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe561538-118f-4c17-b6cc-54460d44f063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge Features (Transaction Amounts):\n",
      "tensor([9.8396e+03, 1.8643e+03, 1.8100e+02,  ..., 6.3114e+06, 8.5000e+05,\n",
      "        8.5000e+05])\n"
     ]
    }
   ],
   "source": [
    "# Assuming that you have edge features like transaction amounts or fraud status\n",
    "edge_features = g.edata.get('amount', None)  # Assuming 'amount' is an edge feature\n",
    "if edge_features is not None:\n",
    "    print(\"Edge Features (Transaction Amounts):\")\n",
    "    print(edge_features)\n",
    "else:\n",
    "    print(\"No edge features found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecd2e705-81a6-4e96-a46a-7e8af83ea77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 80% of nodes for training\n",
    "num_train_nodes = int(0.8 * num_nodes)\n",
    "train_indices = torch.randperm(num_nodes)[:num_train_nodes]  \n",
    "test_indices = torch.tensor([i for i in range(num_nodes) if i not in train_indices])\n",
    "\n",
    "# Create train/test masks\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "train_mask[train_indices] = True\n",
    "test_mask[test_indices] = True\n",
    "\n",
    "# Assign to graph\n",
    "g.ndata['train_mask'] = train_mask\n",
    "g.ndata['test_mask'] = test_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b521fd7-bdfd-47eb-a894-4f4175fd2ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GraphSAGE model for fraud detection\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_feats, out_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.layer1 = dgl.nn.SAGEConv(in_feats, hidden_feats, 'mean')\n",
    "        self.layer2 = dgl.nn.SAGEConv(hidden_feats, out_feats, 'mean')\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        #self.fc = nn.Linear(out_feats * 2, 1)  # * Concatenate source and destination node embeddings *\n",
    "        self.fc = nn.Linear(out_feats, 1)  # Output a single value per node (fraud score)\n",
    "        \n",
    "    def forward(self, g, features):\n",
    "        # Apply first GraphSAGE layer and ReLU\n",
    "        x = self.layer1(g, features)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Apply second GraphSAGE layer to get node embeddings\n",
    "        x = self.layer2(g, x)\n",
    "        \n",
    "        # Output a prediction for each node\n",
    "        logits = self.fc(x).squeeze()  # Output a single value per node\n",
    "        return logits\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "caf5f966-4635-469e-a2d6-2bf70d46c371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud count: 8213\n",
      "Non-fraud count: 63545\n",
      "Fraud ratio: 0.1145\n",
      "Non-fraud ratio: 0.8855\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each label in the 'isFraud' column\n",
    "label_counts = df['isFraud'].value_counts()\n",
    "\n",
    "# Calculate the proportion of each class\n",
    "fraud_ratio = label_counts[1] / len(df)  # Assuming '1' represents fraud\n",
    "non_fraud_ratio = label_counts[0] / len(df)  # Assuming '0' represents non-fraud\n",
    "\n",
    "# Print the results\n",
    "print(f\"Fraud count: {label_counts[1]}\")\n",
    "print(f\"Non-fraud count: {label_counts[0]}\")\n",
    "print(f\"Fraud ratio: {fraud_ratio:.4f}\")\n",
    "print(f\"Non-fraud ratio: {non_fraud_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9f542233-e155-4918-8816-b1e3e427d999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/500, Loss: 47921.22265625\n",
      "Epoch 4/500, Loss: 39687.96484375\n",
      "Epoch 6/500, Loss: 37619.66796875\n",
      "Epoch 8/500, Loss: 35301.21484375\n",
      "Epoch 10/500, Loss: 30839.109375\n",
      "Epoch 12/500, Loss: 25650.013671875\n",
      "Epoch 14/500, Loss: 22829.36328125\n",
      "Epoch 16/500, Loss: 20367.923828125\n",
      "Epoch 18/500, Loss: 18089.52734375\n",
      "Epoch 20/500, Loss: 15483.5927734375\n",
      "Epoch 22/500, Loss: 13198.19140625\n",
      "Epoch 24/500, Loss: 11525.34375\n",
      "Epoch 26/500, Loss: 10087.826171875\n",
      "Epoch 28/500, Loss: 9007.10546875\n",
      "Epoch 30/500, Loss: 7441.970703125\n",
      "Epoch 32/500, Loss: 6485.3017578125\n",
      "Epoch 34/500, Loss: 5609.36669921875\n",
      "Epoch 36/500, Loss: 4707.572265625\n",
      "Epoch 38/500, Loss: 4160.53466796875\n",
      "Epoch 40/500, Loss: 3516.136474609375\n",
      "Epoch 42/500, Loss: 2858.872802734375\n",
      "Epoch 44/500, Loss: 2491.894775390625\n",
      "Epoch 46/500, Loss: 2059.46484375\n",
      "Epoch 48/500, Loss: 1907.142822265625\n",
      "Epoch 50/500, Loss: 1561.1181640625\n",
      "Epoch 52/500, Loss: 1295.8280029296875\n",
      "Epoch 54/500, Loss: 1154.3560791015625\n",
      "Epoch 56/500, Loss: 914.5327758789062\n",
      "Epoch 58/500, Loss: 734.5503540039062\n",
      "Epoch 60/500, Loss: 730.8816528320312\n",
      "Epoch 62/500, Loss: 634.8427734375\n",
      "Epoch 64/500, Loss: 704.45703125\n",
      "Epoch 66/500, Loss: 487.5734558105469\n",
      "Epoch 68/500, Loss: 452.3714904785156\n",
      "Epoch 70/500, Loss: 317.9822998046875\n",
      "Epoch 72/500, Loss: 267.5518798828125\n",
      "Epoch 74/500, Loss: 250.0150146484375\n",
      "Epoch 76/500, Loss: 189.83157348632812\n",
      "Epoch 78/500, Loss: 219.64956665039062\n",
      "Epoch 80/500, Loss: 136.38682556152344\n",
      "Epoch 82/500, Loss: 125.06430053710938\n",
      "Epoch 84/500, Loss: 87.21990966796875\n",
      "Epoch 86/500, Loss: 68.183349609375\n",
      "Epoch 88/500, Loss: 61.595855712890625\n",
      "Epoch 90/500, Loss: 47.26324462890625\n",
      "Epoch 92/500, Loss: 43.7119026184082\n",
      "Epoch 94/500, Loss: 58.34438705444336\n",
      "Epoch 96/500, Loss: 90.24622344970703\n",
      "Epoch 98/500, Loss: 84.36907958984375\n",
      "Epoch 100/500, Loss: 71.215087890625\n",
      "Epoch 102/500, Loss: 101.49948120117188\n",
      "Epoch 104/500, Loss: 47.33546829223633\n",
      "Epoch 106/500, Loss: 38.94184494018555\n",
      "Epoch 108/500, Loss: 73.23336029052734\n",
      "Epoch 110/500, Loss: 68.27529907226562\n",
      "Epoch 112/500, Loss: 53.41720962524414\n",
      "Epoch 114/500, Loss: 21.334575653076172\n",
      "Epoch 116/500, Loss: 65.77751922607422\n",
      "Epoch 118/500, Loss: 65.89228057861328\n",
      "Epoch 120/500, Loss: 61.21397399902344\n",
      "Epoch 122/500, Loss: 106.36154174804688\n",
      "Epoch 124/500, Loss: 70.04662322998047\n",
      "Epoch 126/500, Loss: 53.64069366455078\n",
      "Epoch 128/500, Loss: 50.848514556884766\n",
      "Epoch 130/500, Loss: 79.63346862792969\n",
      "Epoch 132/500, Loss: 82.0789566040039\n",
      "Epoch 134/500, Loss: 56.513179779052734\n",
      "Epoch 136/500, Loss: 30.051925659179688\n",
      "Epoch 138/500, Loss: 51.012447357177734\n",
      "Epoch 140/500, Loss: 81.59677124023438\n",
      "Epoch 142/500, Loss: 75.20831298828125\n",
      "Epoch 144/500, Loss: 27.050575256347656\n",
      "Epoch 146/500, Loss: 48.66568374633789\n",
      "Epoch 148/500, Loss: 45.900108337402344\n",
      "Epoch 150/500, Loss: 45.58872604370117\n",
      "Epoch 152/500, Loss: 24.803499221801758\n",
      "Epoch 154/500, Loss: 32.12737274169922\n",
      "Epoch 156/500, Loss: 28.42551040649414\n",
      "Epoch 158/500, Loss: 47.59199523925781\n",
      "Epoch 160/500, Loss: 31.289941787719727\n",
      "Epoch 162/500, Loss: 53.957008361816406\n",
      "Epoch 164/500, Loss: 35.85813903808594\n",
      "Epoch 166/500, Loss: 48.292640686035156\n",
      "Epoch 168/500, Loss: 53.99382781982422\n",
      "Epoch 170/500, Loss: 74.61856842041016\n",
      "Epoch 172/500, Loss: 73.69425201416016\n",
      "Epoch 174/500, Loss: 64.02519226074219\n",
      "Epoch 176/500, Loss: 59.890716552734375\n",
      "Epoch 178/500, Loss: 86.13985443115234\n",
      "Epoch 180/500, Loss: 63.08625030517578\n",
      "Epoch 182/500, Loss: 101.23035430908203\n",
      "Epoch 184/500, Loss: 78.52234649658203\n",
      "Epoch 186/500, Loss: 65.47277069091797\n",
      "Epoch 188/500, Loss: 66.58074951171875\n",
      "Epoch 190/500, Loss: 35.95839309692383\n",
      "Epoch 192/500, Loss: 22.17291259765625\n",
      "Epoch 194/500, Loss: 30.738468170166016\n",
      "Epoch 196/500, Loss: 42.2092170715332\n",
      "Epoch 198/500, Loss: 22.265077590942383\n",
      "Epoch 200/500, Loss: 33.786529541015625\n",
      "Epoch 202/500, Loss: 31.33845329284668\n",
      "Epoch 204/500, Loss: 60.34598159790039\n",
      "Epoch 206/500, Loss: 68.95521545410156\n",
      "Epoch 208/500, Loss: 40.2492790222168\n",
      "Epoch 210/500, Loss: 102.36295318603516\n",
      "Epoch 212/500, Loss: 40.40637969970703\n",
      "Epoch 214/500, Loss: 104.14203643798828\n",
      "Epoch 216/500, Loss: 19.238697052001953\n",
      "Epoch 218/500, Loss: 64.46797943115234\n",
      "Epoch 220/500, Loss: 61.68459701538086\n",
      "Epoch 222/500, Loss: 42.55303955078125\n",
      "Epoch 224/500, Loss: 63.63179016113281\n",
      "Epoch 226/500, Loss: 21.34308624267578\n",
      "Epoch 228/500, Loss: 33.94014358520508\n",
      "Epoch 230/500, Loss: 57.5935173034668\n",
      "Epoch 232/500, Loss: 30.2451114654541\n",
      "Epoch 234/500, Loss: 35.453914642333984\n",
      "Epoch 236/500, Loss: 57.144256591796875\n",
      "Epoch 238/500, Loss: 63.62889862060547\n",
      "Epoch 240/500, Loss: 23.228429794311523\n",
      "Epoch 242/500, Loss: 22.198040008544922\n",
      "Epoch 244/500, Loss: 41.05885314941406\n",
      "Epoch 246/500, Loss: 39.46829605102539\n",
      "Epoch 248/500, Loss: 39.268341064453125\n",
      "Epoch 250/500, Loss: 19.473711013793945\n",
      "Epoch 252/500, Loss: 19.580413818359375\n",
      "Epoch 254/500, Loss: 27.7615966796875\n",
      "Epoch 256/500, Loss: 21.9504451751709\n",
      "Epoch 258/500, Loss: 19.587474822998047\n",
      "Epoch 260/500, Loss: 13.23398208618164\n",
      "Epoch 262/500, Loss: 4.017421722412109\n",
      "Epoch 264/500, Loss: 15.247404098510742\n",
      "Epoch 266/500, Loss: 4.976502895355225\n",
      "Epoch 268/500, Loss: 21.616825103759766\n",
      "Epoch 270/500, Loss: 23.30402183532715\n",
      "Epoch 272/500, Loss: 32.581031799316406\n",
      "Epoch 274/500, Loss: 11.931719779968262\n",
      "Epoch 276/500, Loss: 20.212495803833008\n",
      "Epoch 278/500, Loss: 37.858436584472656\n",
      "Epoch 280/500, Loss: 25.255910873413086\n",
      "Epoch 282/500, Loss: 13.811782836914062\n",
      "Epoch 284/500, Loss: 43.33846664428711\n",
      "Epoch 286/500, Loss: 45.703617095947266\n",
      "Epoch 288/500, Loss: 21.77910041809082\n",
      "Epoch 290/500, Loss: 16.18449592590332\n",
      "Epoch 292/500, Loss: 37.425724029541016\n",
      "Epoch 294/500, Loss: 32.82908630371094\n",
      "Epoch 296/500, Loss: 14.223626136779785\n",
      "Epoch 298/500, Loss: 9.250381469726562\n",
      "Epoch 300/500, Loss: 9.593475341796875\n",
      "Epoch 302/500, Loss: 20.0428409576416\n",
      "Epoch 304/500, Loss: 20.280635833740234\n",
      "Epoch 306/500, Loss: 14.495980262756348\n",
      "Epoch 308/500, Loss: 15.470597267150879\n",
      "Epoch 310/500, Loss: 14.452632904052734\n",
      "Epoch 312/500, Loss: 14.184879302978516\n",
      "Epoch 314/500, Loss: 16.691064834594727\n",
      "Epoch 316/500, Loss: 15.132482528686523\n",
      "Epoch 318/500, Loss: 16.24481201171875\n",
      "Epoch 320/500, Loss: 23.80632209777832\n",
      "Epoch 322/500, Loss: 17.18729019165039\n",
      "Epoch 324/500, Loss: 18.847442626953125\n",
      "Epoch 326/500, Loss: 15.638071060180664\n",
      "Epoch 328/500, Loss: 21.45186996459961\n",
      "Epoch 330/500, Loss: 14.502126693725586\n",
      "Epoch 332/500, Loss: 22.593311309814453\n",
      "Epoch 334/500, Loss: 6.187724590301514\n",
      "Epoch 336/500, Loss: 9.353874206542969\n",
      "Epoch 338/500, Loss: 36.174400329589844\n",
      "Epoch 340/500, Loss: 27.387771606445312\n",
      "Epoch 342/500, Loss: 12.717182159423828\n",
      "Epoch 344/500, Loss: 48.48543167114258\n",
      "Epoch 346/500, Loss: 12.520320892333984\n",
      "Epoch 348/500, Loss: 27.214635848999023\n",
      "Epoch 350/500, Loss: 28.184856414794922\n",
      "Epoch 352/500, Loss: 27.683971405029297\n",
      "Epoch 354/500, Loss: 11.269195556640625\n",
      "Epoch 356/500, Loss: 8.900358200073242\n",
      "Epoch 358/500, Loss: 18.634769439697266\n",
      "Epoch 360/500, Loss: 7.778668403625488\n",
      "Epoch 362/500, Loss: 7.215843677520752\n",
      "Epoch 364/500, Loss: 32.105865478515625\n",
      "Epoch 366/500, Loss: 21.980331420898438\n",
      "Epoch 368/500, Loss: 12.332418441772461\n",
      "Epoch 370/500, Loss: 33.99323654174805\n",
      "Epoch 372/500, Loss: 4.287068843841553\n",
      "Epoch 374/500, Loss: 12.240265846252441\n",
      "Epoch 376/500, Loss: 9.612719535827637\n",
      "Epoch 378/500, Loss: 12.451332092285156\n",
      "Epoch 380/500, Loss: 19.77214241027832\n",
      "Epoch 382/500, Loss: 20.897645950317383\n",
      "Epoch 384/500, Loss: 29.055665969848633\n",
      "Epoch 386/500, Loss: 19.71079444885254\n",
      "Epoch 388/500, Loss: 15.502145767211914\n",
      "Epoch 390/500, Loss: 15.626108169555664\n",
      "Epoch 392/500, Loss: 12.686853408813477\n",
      "Epoch 394/500, Loss: 10.930471420288086\n",
      "Epoch 396/500, Loss: 16.57427978515625\n",
      "Epoch 398/500, Loss: 11.185160636901855\n",
      "Epoch 400/500, Loss: 13.159019470214844\n",
      "Epoch 402/500, Loss: 7.205057144165039\n",
      "Epoch 404/500, Loss: 2.822439432144165\n",
      "Epoch 406/500, Loss: 9.370399475097656\n",
      "Epoch 408/500, Loss: 12.811666488647461\n",
      "Epoch 410/500, Loss: 17.169496536254883\n",
      "Epoch 412/500, Loss: 8.969844818115234\n",
      "Epoch 414/500, Loss: 4.589539051055908\n",
      "Epoch 416/500, Loss: 8.511024475097656\n",
      "Epoch 418/500, Loss: 6.3050665855407715\n",
      "Epoch 420/500, Loss: 9.932536125183105\n",
      "Epoch 422/500, Loss: 16.806119918823242\n",
      "Epoch 424/500, Loss: 12.38226318359375\n",
      "Epoch 426/500, Loss: 22.963790893554688\n",
      "Epoch 428/500, Loss: 10.576478004455566\n",
      "Epoch 430/500, Loss: 11.632282257080078\n",
      "Epoch 432/500, Loss: 13.394145965576172\n",
      "Epoch 434/500, Loss: 10.011228561401367\n",
      "Epoch 436/500, Loss: 8.008757591247559\n",
      "Epoch 438/500, Loss: 10.186789512634277\n",
      "Epoch 440/500, Loss: 4.725661754608154\n",
      "Epoch 442/500, Loss: 5.66489839553833\n",
      "Epoch 444/500, Loss: 4.56483268737793\n",
      "Epoch 446/500, Loss: 7.424166202545166\n",
      "Epoch 448/500, Loss: 11.411361694335938\n",
      "Epoch 450/500, Loss: 14.350579261779785\n",
      "Epoch 452/500, Loss: 11.237738609313965\n",
      "Epoch 454/500, Loss: 18.21319580078125\n",
      "Epoch 456/500, Loss: 17.11224937438965\n",
      "Epoch 458/500, Loss: 8.868627548217773\n",
      "Epoch 460/500, Loss: 19.276758193969727\n",
      "Epoch 462/500, Loss: 14.438896179199219\n",
      "Epoch 464/500, Loss: 9.693072319030762\n",
      "Epoch 466/500, Loss: 14.9296236038208\n",
      "Epoch 468/500, Loss: 12.90777587890625\n",
      "Epoch 470/500, Loss: 3.31689715385437\n",
      "Epoch 472/500, Loss: 19.427141189575195\n",
      "Epoch 474/500, Loss: 16.640989303588867\n",
      "Epoch 476/500, Loss: 15.279611587524414\n",
      "Epoch 478/500, Loss: 13.47546100616455\n",
      "Epoch 480/500, Loss: 8.47857666015625\n",
      "Epoch 482/500, Loss: 4.782466411590576\n",
      "Epoch 484/500, Loss: 14.852721214294434\n",
      "Epoch 486/500, Loss: 17.75553321838379\n",
      "Epoch 488/500, Loss: 12.123291969299316\n",
      "Epoch 490/500, Loss: 6.1573686599731445\n",
      "Epoch 492/500, Loss: 9.702133178710938\n",
      "Epoch 494/500, Loss: 5.7983551025390625\n",
      "Epoch 496/500, Loss: 10.46849250793457\n",
      "Epoch 498/500, Loss: 6.007519245147705\n",
      "Epoch 500/500, Loss: 5.559237957000732\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "in_feats = 2  # balanceOrig and balanceDest features\n",
    "hidden_feats = 64\n",
    "out_feats = 1  # Fraud (binary classification)\n",
    "\n",
    "#pos_weight = torch.tensor([non_fraud_ratio/fraud_ratio],dtype=torch.float)\n",
    "pos_weight = torch.tensor([1.0],dtype=torch.float)\n",
    "\n",
    "\n",
    "model = GraphSAGE(in_feats, hidden_feats, out_feats)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "epochs = 500\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    # Forward pass\n",
    "    logits = model(g, g.ndata['features'])\n",
    "    #print(logits.shape)\n",
    "\n",
    "    # Get target labels for the fraud detection task\n",
    "    labels = g.ndata['isFraud']\n",
    "    # Compute loss (use train_mask to filter out test edges)\n",
    "    #print(\"labels\",labels[train_mask].view(-1,1).shape)\n",
    "    #print(\"logits\", logits[train_mask].view(-1,1).shape)\n",
    "    loss = loss_fn(logits[train_mask].view(-1,1), labels[train_mask].view(-1,1))\n",
    "    \n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss every few epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c15695-ca6e-49ef-81e7-b66b7618a1d7",
   "metadata": {},
   "source": [
    "Epoch 2/20, Loss: 50026236.0\n",
    "Epoch 4/20, Loss: 21910472.0\n",
    "Epoch 6/20, Loss: 12671362.0\n",
    "Epoch 8/20, Loss: 12492275.0\n",
    "Epoch 10/20, Loss: 13373789.0\n",
    "Epoch 12/20, Loss: 14267830.0\n",
    "Epoch 14/20, Loss: 14137046.0\n",
    "Epoch 16/20, Loss: 12949893.0\n",
    "Epoch 18/20, Loss: 11810090.0\n",
    "Epoch 20/20, Loss: 10091464.0\n",
    "0.1\n",
    "Accuracy: 0.7332\n",
    "Recall: 0.0086\n",
    "F1 Score: 0.0073\n",
    "0.01\n",
    "Accuracy: 0.7535\n",
    "Recall: 0.0039\n",
    "F1 Score: 0.0036\n",
    "0.2\n",
    "Accuracy: 0.7378\n",
    "Recall: 0.0102\n",
    "F1 Score: 0.0087\n",
    "0.4\n",
    "Accuracy: 0.7405\n",
    "Recall: 0.0079\n",
    "F1 Score: 0.0068"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d073edc-243e-4b6e-9d3e-9ac7d47ce144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['features', 'isFraud', 'train_mask', 'test_mask'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.ndata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "45d2bbf5-bda6-484a-9a51-8faaab1820ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[      0.0000,  137508.0156],\n",
      "        [      0.0000,    9458.1602],\n",
      "        [  43935.0586,       0.0000],\n",
      "        ...,\n",
      "        [1375603.2500,       0.0000],\n",
      "        [3523089.5000,       0.0000],\n",
      "        [5338583.5000,       0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(g.ndata['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23e85df0-9f6b-456d-82b1-b8e41577a6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8480\n",
      "Recall: 0.4511\n",
      "Precision:0.4586\n",
      "F1 Score: 0.4548\n",
      "Sample transaction mappings with user names:\n",
      "{'orig_user': 'C1254777952', 'predicted_label': 1, 'true_label': 1, 'avg_amount_orig': 0.0, 'avg_amount_dest': 137508.015625}\n",
      "{'orig_user': 'C1663444510', 'predicted_label': 0, 'true_label': 0, 'avg_amount_orig': 76514.0390625, 'avg_amount_dest': 0.0}\n",
      "{'orig_user': 'C1199402854', 'predicted_label': 0, 'true_label': 0, 'avg_amount_orig': 2962.06005859375, 'avg_amount_dest': 0.0}\n",
      "{'orig_user': 'M489771107', 'predicted_label': 0, 'true_label': 0, 'avg_amount_orig': 0.0, 'avg_amount_dest': 5349.259765625}\n",
      "{'orig_user': 'C888357097', 'predicted_label': 1, 'true_label': 1, 'avg_amount_orig': 0.0, 'avg_amount_dest': 128893.5}\n",
      "{'orig_user': 'C674306325', 'predicted_label': 1, 'true_label': 1, 'avg_amount_orig': 0.0, 'avg_amount_dest': 722832.9375}\n",
      "{'orig_user': 'C717624927', 'predicted_label': 0, 'true_label': 0, 'avg_amount_orig': 315270.71875, 'avg_amount_dest': 0.0}\n",
      "{'orig_user': 'M1776042738', 'predicted_label': 0, 'true_label': 0, 'avg_amount_orig': 0.0, 'avg_amount_dest': 1214.27001953125}\n",
      "{'orig_user': 'C1474689842', 'predicted_label': 0, 'true_label': 0, 'avg_amount_orig': 327568.9375, 'avg_amount_dest': 0.0}\n",
      "{'orig_user': 'M660756936', 'predicted_label': 0, 'true_label': 0, 'avg_amount_orig': 0.0, 'avg_amount_dest': 13835.9599609375}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(g, g.ndata['features'])\n",
    "\n",
    "    # Convert logits to probabilities\n",
    "    predictions = torch.sigmoid(logits).squeeze()\n",
    "    \n",
    "    # Apply threshold of to classify fraud\n",
    "    predicted_labels = (predictions > 0.5).float()\n",
    "    predicted_labels = predicted_labels[test_mask]  # Apply test_mask here\n",
    "    # Get actual labels\n",
    "    #true_labels = g.edata['isFraud']\n",
    "    true_labels = g.ndata['isFraud'][test_mask]  # Apply test_mask here\n",
    "    #amounts=g.ndata['amount'][test_mask]\n",
    "    # Store results in a list of dictionaries\n",
    "    # Convert node indices back to user names\n",
    "    reverse_user_mapping = {v: k for k, v in user_mapping.items()}  # Reverse mapping\n",
    "    \n",
    "    # Retrieve node indices from test_mask\n",
    "    test_node_indices = test_mask.nonzero().squeeze().tolist()\n",
    "\n",
    "    node_features_test = g.ndata['features'][test_mask]  # Shape: (num_test_nodes, 2)\n",
    "    \n",
    "    avg_amount_orig_test = node_features_test[:, 0].tolist()\n",
    "    avg_amount_dest_test = node_features_test[:, 1].tolist()\n",
    "    \n",
    "    # Map predictions back to transactions with their original balances\n",
    "    mapped_results = [\n",
    "        {\n",
    "            \"orig_user\": reverse_user_mapping[node],\n",
    "            \"predicted_label\": int(pred),\n",
    "            \"true_label\": int(true_lab),\n",
    "            \"avg_amount_orig\": avg_amount_orig,\n",
    "            \"avg_amount_dest\": avg_amount_dest\n",
    "        }\n",
    "        for node, pred, true_lab, avg_amount_orig, avg_amount_dest in zip(\n",
    "            test_node_indices, predicted_labels.tolist(), true_labels.tolist(), avg_amount_orig_test, avg_amount_dest_test\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Compute accuracy manually\n",
    "    correct = (predicted_labels == true_labels).sum().item()\n",
    "    total = true_labels.size(0)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    # Print evaluation results\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    # Calculate F1-Score\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Precision:{precision:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "# Print some mapped results\n",
    "print(\"Sample transaction mappings with user names:\")\n",
    "for res in mapped_results[:10]:\n",
    "    print(res)\n",
    "    #if res['balance_orig']>0 and res['balance_dest']>0:\n",
    "    #    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1c244cd-c6db-48cc-b2b6-56fd33b2d3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[      0.0000,  137508.0156],\n",
      "        [      0.0000,    9458.1602],\n",
      "        [  43935.0586,       0.0000],\n",
      "        ...,\n",
      "        [1375603.2500,       0.0000],\n",
      "        [3523089.5000,       0.0000],\n",
      "        [5338583.5000,       0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "207ba890-7fc4-4444-a169-f08dfebd5356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16301)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(labels==1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
